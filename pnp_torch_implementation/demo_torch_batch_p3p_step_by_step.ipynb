{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import torch\n",
    "\n",
    "batch_size = 5 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At first we have : \n",
    "- camera's parameters -> A (focal, center) \n",
    "- rotation matrix  -> R \n",
    "- position matrix -> C \n",
    "- 3D points position ->  P1 P2 P3 (and P4 to determinate the best solution after P3P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A = \n",
      " tensor([[800.,   0., 320.],\n",
      "        [  0., 800., 240.],\n",
      "        [  0.,   0.,   1.]], dtype=torch.float64)\n",
      "torch.Size([3, 3])\n",
      "A_batch = \n",
      " tensor([[[800.,   0., 320.],\n",
      "         [  0., 800., 240.],\n",
      "         [  0.,   0.,   1.]],\n",
      "\n",
      "        [[800.,   0., 320.],\n",
      "         [  0., 800., 240.],\n",
      "         [  0.,   0.,   1.]],\n",
      "\n",
      "        [[800.,   0., 320.],\n",
      "         [  0., 800., 240.],\n",
      "         [  0.,   0.,   1.]],\n",
      "\n",
      "        [[800.,   0., 320.],\n",
      "         [  0., 800., 240.],\n",
      "         [  0.,   0.,   1.]],\n",
      "\n",
      "        [[800.,   0., 320.],\n",
      "         [  0., 800., 240.],\n",
      "         [  0.,   0.,   1.]]], dtype=torch.float64)\n",
      "torch.Size([5, 3, 3])\n",
      "R = \n",
      " tensor([[ 1.,  0.,  0.],\n",
      "        [ 0., -1.,  0.],\n",
      "        [ 0.,  0., -1.]], dtype=torch.float64)\n",
      "torch.Size([3, 3])\n",
      "R_batch = \n",
      " tensor([[[ 1.,  0.,  0.],\n",
      "         [ 0., -1.,  0.],\n",
      "         [ 0.,  0., -1.]],\n",
      "\n",
      "        [[ 1.,  0.,  0.],\n",
      "         [ 0., -1.,  0.],\n",
      "         [ 0.,  0., -1.]],\n",
      "\n",
      "        [[ 1.,  0.,  0.],\n",
      "         [ 0., -1.,  0.],\n",
      "         [ 0.,  0., -1.]],\n",
      "\n",
      "        [[ 1.,  0.,  0.],\n",
      "         [ 0., -1.,  0.],\n",
      "         [ 0.,  0., -1.]],\n",
      "\n",
      "        [[ 1.,  0.,  0.],\n",
      "         [ 0., -1.,  0.],\n",
      "         [ 0.,  0., -1.]]], dtype=torch.float64)\n",
      "torch.Size([5, 3, 3])\n",
      "C = \n",
      " tensor([[0., 0., 6.]], dtype=torch.float64)\n",
      "torch.Size([1, 3])\n",
      "C_batch = \n",
      " tensor([[0., 0., 6.],\n",
      "        [0., 0., 6.],\n",
      "        [0., 0., 6.],\n",
      "        [0., 0., 6.],\n",
      "        [0., 0., 6.]], dtype=torch.float64)\n",
      "torch.Size([5, 3])\n"
     ]
    }
   ],
   "source": [
    "# This script defines the camera parameters, rotation matrix, and translation matrix.\n",
    "def camera() : \n",
    "  # Definition of the camera parameters\n",
    "  # focal length\n",
    "  fx = 800\n",
    "  fy = 800\n",
    "  # center\n",
    "  cx = 320 \n",
    "  cy = 240\n",
    "\n",
    "  A = torch.tensor([[fx, 0, cx], [0, fy, cy], [0, 0, 1]], dtype=torch.float64) # intraseca matrix of the camera (3*3)\n",
    "  #A = torch.from_numpy(A)  # Convert to a PyTorch tensor\n",
    "  print(\"A = \\n\", A)\n",
    "  print(A.shape)  # (3*3)\n",
    "  A_batch = A.repeat(batch_size,1,1)\n",
    "  print(\"A_batch = \\n\", A_batch)\n",
    "  print(A_batch.shape)  # (batch_size, 3, 3)\n",
    "  return A_batch\n",
    "\n",
    "A = camera() \n",
    "\n",
    "\n",
    "\n",
    "def rotation_matrix() : \n",
    "  # Definition of the rotation matrix of the camera \n",
    "  R = torch.tensor([[1, 0, 0],[0, -1, 0], [0, 0, -1]], dtype=torch.float64)  # (3*3)\n",
    "  #R = torch.from_numpy(R)  # Convert to a PyTorch tensor\n",
    "  print(\"R = \\n\",R)\n",
    "  print(R.shape)  # (3*3)\n",
    "  R_batch = R.repeat(batch_size,1,1)  # Repeat the rotation matrix for each batch\n",
    "  print(\"R_batch = \\n\", R_batch)  \n",
    "  print(R_batch.shape)  # (batch_size, 3, 3)\n",
    "  return R_batch\n",
    "\n",
    "def camera_position() : \n",
    "  # Definition of the translation matrix of the camera (the position)\n",
    "  C = torch.tensor([[0,0,6]], dtype=torch.float64)    # T = [tx,ty,tz]  (1*3)\n",
    "  print(\"C = \\n\",C)\n",
    "  print(C.shape)  # (1*3)\n",
    "\n",
    "  C_batch = C.repeat(batch_size, 1)  # Repeat the translation vector for each batch\n",
    "  print(\"C_batch = \\n\", C_batch)  \n",
    "  print(C_batch.shape)  # (batch_size, 3)\n",
    "\n",
    " \n",
    "  return C_batch\n",
    "\n",
    "R = rotation_matrix()\n",
    "C = camera_position()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "points3D = \n",
      " tensor([[ 0.5809, -0.1600, -0.2529],\n",
      "        [-0.9100, -0.1778,  0.0302],\n",
      "        [ 0.4908,  1.0280, -0.3566],\n",
      "        [ 1.8488, -0.7180, -0.9518]])\n",
      "torch.Size([4, 3])\n",
      "points3D = \n",
      " tensor([[ 0.6384, -1.7285, -0.6817],\n",
      "        [-0.1626, -0.0539, -1.1291],\n",
      "        [-0.2243, -1.9960, -1.4533],\n",
      "        [ 1.0999,  0.9221,  1.6678]])\n",
      "torch.Size([4, 3])\n",
      "points3D = \n",
      " tensor([[-0.7532,  1.4582, -1.5701],\n",
      "        [-1.2716,  0.6983, -0.5325],\n",
      "        [-0.6419, -0.0864, -0.4413],\n",
      "        [-1.8953,  1.7584, -0.0053]])\n",
      "torch.Size([4, 3])\n",
      "points3D = \n",
      " tensor([[-1.8223, -1.2637,  1.7288],\n",
      "        [-1.6803,  0.9148,  0.2451],\n",
      "        [ 0.6108,  1.1212,  1.9780],\n",
      "        [ 0.9886, -1.7289,  0.2284]])\n",
      "torch.Size([4, 3])\n",
      "points3D = \n",
      " tensor([[ 1.3985,  1.5775, -1.3829],\n",
      "        [-0.4063, -0.9708,  0.9838],\n",
      "        [-1.1582,  0.6216, -0.3719],\n",
      "        [-1.4580, -1.2597, -0.6311]])\n",
      "torch.Size([4, 3])\n",
      "points3D_batch = \n",
      " tensor([[[ 0.5809, -0.1600, -0.2529],\n",
      "         [-0.9100, -0.1778,  0.0302],\n",
      "         [ 0.4908,  1.0280, -0.3566],\n",
      "         [ 1.8488, -0.7180, -0.9518]],\n",
      "\n",
      "        [[ 0.6384, -1.7285, -0.6817],\n",
      "         [-0.1626, -0.0539, -1.1291],\n",
      "         [-0.2243, -1.9960, -1.4533],\n",
      "         [ 1.0999,  0.9221,  1.6678]],\n",
      "\n",
      "        [[-0.7532,  1.4582, -1.5701],\n",
      "         [-1.2716,  0.6983, -0.5325],\n",
      "         [-0.6419, -0.0864, -0.4413],\n",
      "         [-1.8953,  1.7584, -0.0053]],\n",
      "\n",
      "        [[-1.8223, -1.2637,  1.7288],\n",
      "         [-1.6803,  0.9148,  0.2451],\n",
      "         [ 0.6108,  1.1212,  1.9780],\n",
      "         [ 0.9886, -1.7289,  0.2284]],\n",
      "\n",
      "        [[ 1.3985,  1.5775, -1.3829],\n",
      "         [-0.4063, -0.9708,  0.9838],\n",
      "         [-1.1582,  0.6216, -0.3719],\n",
      "         [-1.4580, -1.2597, -0.6311]]])\n",
      "torch.Size([5, 4, 3])\n",
      "P1 = \n",
      " tensor([[-0.4147,  0.2234, -1.1711],\n",
      "        [ 0.9477, -0.2189,  1.8360],\n",
      "        [-0.6812,  0.7641, -0.0831],\n",
      "        [-1.3915, -0.9533,  1.5606],\n",
      "        [-1.5090,  1.4747, -0.2659]])\n",
      "torch.Size([5, 3])\n"
     ]
    }
   ],
   "source": [
    "# Definition of 3D points in the world coordinate system\n",
    "def point3Daleatoire(x) :\n",
    "  # Generation of one random points in 3D space \n",
    "  return torch.tensor([[np.random.uniform(-x,x),np.random.uniform(-x,x),np.random.uniform(-x,x)]])\n",
    "\n",
    "def pts_3D_4pts():\n",
    "  # Generate randomly 4 3D points\n",
    "  # Output : tensor which concatenate the 4 points = [ P1, P2, P3, P4 ] \n",
    "\n",
    "  P1 = point3Daleatoire(2)     # (1*3) -> pour P3P\n",
    "  P2 = point3Daleatoire(2)\n",
    "  P3 = point3Daleatoire(2)\n",
    "  P4 = point3Daleatoire(2)\n",
    "  \n",
    "  points3D = torch.cat((P1,P2,P3,P4),dim=0);     # (LIGNES 4* COLONNES 3) - xyz\n",
    "  print(\"points3D = \\n\", points3D)\n",
    "  print(points3D.shape)  # (4*3)\n",
    "\n",
    "  \n",
    "  return points3D\n",
    "\n",
    "def pts_3D_4pts_batch():\n",
    "  # Generate randomly 4 3D points for each batch\n",
    "  # Output : array which concatenate the 4 points = [ P1, P2, P3, P4 ] for each batch\n",
    "\n",
    "  # Generate a batch of random points in 3D space\n",
    "  # Each point is generated independently for each batch\n",
    "\n",
    "  points3D_batch = torch.stack([pts_3D_4pts() for i in range(batch_size)])  # (batch_size, 4, 3)\n",
    "  print(\"points3D_batch = \\n\", points3D_batch)\n",
    "  print(points3D_batch.shape)  # (batch_size, 4, 3)\n",
    "  return points3D_batch\n",
    "\n",
    "points3D_batch = pts_3D_4pts_batch()  # Generate the batch of 3D points\n",
    "'''\n",
    "P1 = torch.tensor([0.7161, 0.5431, 1.7807], dtype=torch.float64)    # (3,)\n",
    "P2 = torch.tensor([-1.1643, 0.8371, -1.0551], dtype=torch.float64)\n",
    "P3 = torch.tensor([-1.5224, 0.4292, -0.1994], dtype=torch.float64)\n",
    "P4 = torch.tensor([-1.5224, 0.4292, -0.1994], dtype=torch.float64) \n",
    "'''\n",
    "P1 = points3D_batch[:, 0, :]  # Extract P1 for each batch\n",
    "P2 = points3D_batch[:, 1, :]  # Extract P2 for each batch\n",
    "P3 = points3D_batch[:, 2, :]  # Extract P3 for each batch\n",
    "P4 = points3D_batch[:, 3, :]  # Extract P4 for each batch\n",
    "\n",
    "print(\"P1 = \\n\", P1_batch)\n",
    "print(P1.shape)  # (batch_size, 3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create the 3 direction features vectors f1, f2, f3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "points3D = \n",
      " [tensor([[-0.4147,  0.2234, -1.1711],\n",
      "        [ 0.9477, -0.2189,  1.8360],\n",
      "        [-0.6812,  0.7641, -0.0831],\n",
      "        [-1.3915, -0.9533,  1.5606],\n",
      "        [-1.5090,  1.4747, -0.2659]]), tensor([[-1.5163,  1.7661,  1.0130],\n",
      "        [ 0.3697,  0.9377,  0.5091],\n",
      "        [-1.8278, -0.8189, -0.1363],\n",
      "        [-0.6372,  0.4595,  0.1571],\n",
      "        [ 0.9308, -0.9215, -0.4567]]), tensor([[-0.2264, -1.4611,  1.2904],\n",
      "        [ 1.8173, -0.3789,  0.5046],\n",
      "        [-1.9600, -0.9082,  0.7163],\n",
      "        [-0.9605,  0.5930,  0.7639],\n",
      "        [ 0.1188, -0.3083, -1.3033]])]\n",
      "P1 = \n",
      " tensor([[[-0.4147],\n",
      "         [ 0.2234],\n",
      "         [-1.1711]],\n",
      "\n",
      "        [[ 0.9477],\n",
      "         [-0.2189],\n",
      "         [ 1.8360]],\n",
      "\n",
      "        [[-0.6812],\n",
      "         [ 0.7641],\n",
      "         [-0.0831]],\n",
      "\n",
      "        [[-1.3915],\n",
      "         [-0.9533],\n",
      "         [ 1.5606]],\n",
      "\n",
      "        [[-1.5090],\n",
      "         [ 1.4747],\n",
      "         [-0.2659]]])\n",
      "torch.Size([5, 3, 1])\n",
      "C = \n",
      " tensor([[[0.],\n",
      "         [0.],\n",
      "         [6.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [6.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [6.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [6.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [6.]]], dtype=torch.float64)\n",
      "torch.Size([5, 3, 1])\n",
      "v1 = \n",
      " tensor([[[-0.4147],\n",
      "         [-0.2234],\n",
      "         [ 7.1711]],\n",
      "\n",
      "        [[ 0.9477],\n",
      "         [ 0.2189],\n",
      "         [ 4.1640]],\n",
      "\n",
      "        [[-0.6812],\n",
      "         [-0.7641],\n",
      "         [ 6.0831]],\n",
      "\n",
      "        [[-1.3915],\n",
      "         [ 0.9533],\n",
      "         [ 4.4394]],\n",
      "\n",
      "        [[-1.5090],\n",
      "         [-1.4747],\n",
      "         [ 6.2659]]], dtype=torch.float64)\n",
      "torch.Size([5, 3, 1])\n",
      "f1 = \n",
      " tensor([[[-0.0577],\n",
      "         [-0.0311],\n",
      "         [ 0.9978]],\n",
      "\n",
      "        [[ 0.2216],\n",
      "         [ 0.0512],\n",
      "         [ 0.9738]],\n",
      "\n",
      "        [[-0.1104],\n",
      "         [-0.1239],\n",
      "         [ 0.9861]],\n",
      "\n",
      "        [[-0.2930],\n",
      "         [ 0.2007],\n",
      "         [ 0.9348]],\n",
      "\n",
      "        [[-0.2282],\n",
      "         [-0.2231],\n",
      "         [ 0.9477]]], dtype=torch.float64)\n",
      "torch.Size([5, 3, 1])\n",
      "f1 :  torch.Size([5, 1, 3])\n",
      "features vectors = \n",
      " tensor([[[-0.0577, -0.0311,  0.9978],\n",
      "         [-0.2755, -0.3209,  0.9062],\n",
      "         [-0.0459,  0.2960,  0.9541]],\n",
      "\n",
      "        [[ 0.2216,  0.0512,  0.9738],\n",
      "         [ 0.0662, -0.1680,  0.9836],\n",
      "         [ 0.3133,  0.0653,  0.9474]],\n",
      "\n",
      "        [[-0.1104, -0.1239,  0.9861],\n",
      "         [-0.2832,  0.1269,  0.9506],\n",
      "         [-0.3434,  0.1591,  0.9256]],\n",
      "\n",
      "        [[-0.2930,  0.2007,  0.9348],\n",
      "         [-0.1081, -0.0779,  0.9911],\n",
      "         [-0.1793, -0.1107,  0.9775]],\n",
      "\n",
      "        [[-0.2282, -0.2231,  0.9477],\n",
      "         [ 0.1413,  0.1399,  0.9800],\n",
      "         [ 0.0162,  0.0422,  0.9990]]], dtype=torch.float64)\n",
      "torch.Size([5, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "def features_vectors(points3D,C, R,batch_size) :\n",
    "    '''\n",
    "    This function computes the features vectors for P3P algorithm.\n",
    "    args:\n",
    "    points3D : array with the 4 3D points = [ P1, P2, P3, P4 ] (4*3) \n",
    "    but we only use the first three points for P3P\n",
    "    C: camera position matrix : (3*1)\n",
    "    returns:\n",
    "    featuresVect : array with the features vectors (9*1)\n",
    "    '''\n",
    "    P1 = torch.reshape(points3D[0], (batch_size,3,1))  # Reshape to (3,1) for easier calculations\n",
    "    print(\"P1 = \\n\", P1)  # Print P1 to check the values\n",
    "    print(P1.shape)  # (batch_size, 3, 1)\n",
    "    P2 = torch.reshape(points3D[1], (batch_size,3,1))\n",
    "    P3 = torch.reshape(points3D[2], (batch_size,3,1))\n",
    "\n",
    "    C = torch.reshape(C, (batch_size,3,1))  # Reshape C to (3,1) for easier calculations\n",
    "    print(\"C = \\n\", C)  # Print C to check the values\n",
    "    print(C.shape)  # (batch_size, 3, 1)\n",
    "\n",
    "    v1 = torch.matmul(R,(P1 - C))  # Calculate the vector from camera to P1\n",
    "    print(\"v1 = \\n\", v1)  # Print v1 to check the values\n",
    "    print(v1.shape)  # (batch_size, 3, 1)\n",
    "    v2 = torch.matmul(R,(P2 - C))  # Calculate the vector from camera to P2\n",
    "    v3 = torch.matmul(R,(P3 - C))  # Calculate the vector from camera to P3\n",
    "\n",
    "    f1 = v1 / torch.norm(v1,dim=1, keepdim=True)  # Normalize the vector v1\n",
    "    f2 = v2 / torch.norm(v2,dim=1, keepdim=True)  # Normalize the vector v2\n",
    "    f3 = v3 / torch.norm(v3,dim=1, keepdim=True)  # Normalize the vector v3\n",
    "\n",
    "    print(\"f1 = \\n\", f1)  # Print f1 to check the values\n",
    "    print(f1.shape)  # (batch_size, 3, 1)\n",
    "\n",
    "    f1 = torch.reshape(f1, (batch_size,1,3))  # Reshape to (3,1)\n",
    "    print(\"f1 : \",f1.shape) # (batch_size,1,3)\n",
    "    f2 = torch.reshape(f2, (batch_size,1,3))\n",
    "    f3 = torch.reshape(f3, (batch_size,1,3))\n",
    "\n",
    "    featuresVect = torch.cat((f1,f2,f3),dim=1)\n",
    "    print(\"features vectors = \\n\",featuresVect)\n",
    "    print(featuresVect.shape)  # (batch_size, 3, 3)\n",
    "\n",
    "    return featuresVect # Return the features vectors need in P3P\n",
    "\n",
    "\n",
    "points3D = [P1_batch, P2_batch, P3_batch]  # We define the points3D with the first three points\n",
    "print(\"points3D = \\n\", points3D)  # Print the points3D to check the values  / List len = 3 \n",
    "\n",
    "\n",
    "featuresVect = features_vectors(points3D, C, R,batch_size)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly we need the functions to resolve the polynomial roots. - for test go to test resolution polynome "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from complex_utils import *\n",
    "\n",
    "\n",
    "def polynomial_root_calculation_4th_degree_ferrari(a): # Ferrari's Method\n",
    "    # Solving a polynomial of 4th degree\n",
    "\n",
    "    # Input : array 5*1 with the 5 coefficiants of the polynomial \n",
    "    # Output : roots of the polynomial a[4]*x^4 + a[3]*x^3 + a[2]*x^2 + a[1]*x + a[0]   -> array : [x1,x2,x3,x4]  (4*1)\n",
    "\n",
    "    if a.numel() != 5 :\n",
    "      print(\"Expeted 5 coefficiants for a 4th order polynomial\")\n",
    "      return\n",
    "\n",
    "    a0, a1, a2, a3, a4 = a      # float\n",
    "\n",
    "    # Reduce the quartic equation to the form : x^4 + a*x^3 + b*x^2 + c*x + d = 0\n",
    "    a = a3/a4           # float \n",
    "    b = a2/a4\n",
    "    c = a1/a4\n",
    "    d = a0/a4\n",
    "\n",
    "    # Computation of the coefficients of the Ferrari's Method\n",
    "    S = a/4\n",
    "    b0 = d - c*S + b* S**2 - 3* S**4\n",
    "    b1 = c - 2*b*S + 8*S**3\n",
    "    b2 = b - 6 * S**2\n",
    "\n",
    "\n",
    "    # Solve the cubic equation m^3 + b2*m^2 + (b2^2/4  - b0)*m - b1^2/8 = 0\n",
    "    x_cube = polynomial_root_calculation_3rd_degree(1,b2,(b2**2)/4-b0,(-b1**2)/8)\n",
    "    \n",
    "\n",
    "    # Find a real and positive solution\n",
    "    alpha_0_nul = True\n",
    "    for r in x_cube :\n",
    "      if torch.isclose(r[1],torch.tensor(0.0,dtype=torch.float64),atol=1e-7) and r[0] > 0 :\n",
    "        alpha_0 = r\n",
    "        alpha_0_nul = False\n",
    "        \n",
    "\n",
    "    if alpha_0_nul == False :   # case where we found a real and positive solution so alpha_0_imag = 0 \n",
    "        alpha0_div_2 = product_complex_real(alpha_0,0.5)\n",
    "        sqrt_alpha = sqrt(alpha0_div_2[0])\n",
    "        term = addition_complex_real(- alpha0_div_2 ,-b2 / 2)\n",
    "        denom = 2 * torch.sqrt(2 * alpha_0)\n",
    "        \n",
    "       \n",
    "        frac = division_2_complex_numbers(torch.tensor([b1, 0.0]), denom)  # b1 is real, so we can use a tensor with 0 imaginary part\n",
    "\n",
    "        x1 = addition_complex_real(sqrt_alpha ,- S) + sqrt_complex(addition(term,-frac))\n",
    "        x2 = addition_complex_real(sqrt_alpha, - S) - sqrt_complex(addition(term,-frac))\n",
    "        x3 = addition_complex_real(-sqrt_alpha, - S) + sqrt_complex(addition(term,frac))\n",
    "        x4 = addition_complex_real(-sqrt_alpha,- S) - sqrt_complex(addition(term,frac))\n",
    "    \n",
    "    else:\n",
    "\n",
    "        sqrt_inner1 = sqrt((b2**2) / 4 - b0)        # complex \n",
    "        x1 = addition_complex_real(sqrt_complex(addition_complex_real(sqrt_inner1,-b2 / 2)),-S)\n",
    "        x2 = addition_complex_real(- sqrt_complex(addition_complex_real(sqrt_inner1,-b2 / 2)),-S)\n",
    "        x3 = addition_complex_real(sqrt_complex(addition_complex_real(- sqrt_inner1,-b2 / 2 )),-S)\n",
    "        x4 = addition_complex_real(- sqrt_complex(addition_complex_real(- sqrt_inner1,-b2 / 2 )),-S)\n",
    "\n",
    "    return [x1, x2, x3, x4]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have all the variables needed for the p3p so we start"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Storage of points : already done "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P1 = \n",
      " tensor([[ 0.5809, -0.1600, -0.2529],\n",
      "        [ 0.6384, -1.7285, -0.6817],\n",
      "        [-0.7532,  1.4582, -1.5701],\n",
      "        [-1.8223, -1.2637,  1.7288],\n",
      "        [ 1.3985,  1.5775, -1.3829]])\n",
      "P2 = \n",
      " tensor([[-0.9100, -0.1778,  0.0302],\n",
      "        [-0.1626, -0.0539, -1.1291],\n",
      "        [-1.2716,  0.6983, -0.5325],\n",
      "        [-1.6803,  0.9148,  0.2451],\n",
      "        [-0.4063, -0.9708,  0.9838]])\n",
      "P3 = \n",
      " tensor([[ 0.4908,  1.0280, -0.3566],\n",
      "        [-0.2243, -1.9960, -1.4533],\n",
      "        [-0.6419, -0.0864, -0.4413],\n",
      "        [ 0.6108,  1.1212,  1.9780],\n",
      "        [-1.1582,  0.6216, -0.3719]])\n"
     ]
    }
   ],
   "source": [
    "print(\"P1 = \\n\", P1)\n",
    "print(\"P2 = \\n\", P2)\n",
    "print(\"P3 = \\n\", P3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Storage of the features vectors : done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 =  tensor([[-0.0577, -0.0311,  0.9978],\n",
      "        [ 0.2216,  0.0512,  0.9738],\n",
      "        [-0.1104, -0.1239,  0.9861],\n",
      "        [-0.2930,  0.2007,  0.9348],\n",
      "        [-0.2282, -0.2231,  0.9477]], dtype=torch.float64)\n",
      "torch.Size([5, 3])\n",
      "f2 =  tensor([[ 0.2216,  0.0512,  0.9738],\n",
      "        [ 0.0662, -0.1680,  0.9836],\n",
      "        [ 0.3133,  0.0653,  0.9474]], dtype=torch.float64)\n",
      "f3 =  tensor([[-0.1104, -0.1239,  0.9861],\n",
      "        [-0.2832,  0.1269,  0.9506],\n",
      "        [-0.3434,  0.1591,  0.9256]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# we got featuresVect and we access the 3 values \n",
    "f1 = featuresVect[:,0,:]  # Access the first feature vector for each batch\n",
    "f2 = featuresVect[1]\n",
    "f3 = featuresVect[2]\n",
    "\n",
    "print(\"f1 = \", f1)\n",
    "print(f1.shape)  # (batsh_size,3)\n",
    "print(\"f2 = \", f2)\n",
    "print(\"f3 = \", f3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Création of a solution variable : maximum 4 solutions  \n",
    "\n",
    "    Matrix (4,3,4)  \n",
    "    Each layer is a solution, for each leayer : first column stres the camera position matrix C (3,1) and the remaining 3 columns store the rotation matrix R (3,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "solutions = \n",
      " tensor([[[[0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0.]]]], dtype=torch.float64)\n",
      "torch.Size([5, 4, 3, 4])\n"
     ]
    }
   ],
   "source": [
    "solutions = torch.zeros((batch_size,4,3,4), dtype=torch.float64)\n",
    "print(\"solutions = \\n\", solutions)\n",
    "print(solutions.shape)  # (4,3,4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Verification that the 3 points given are not collinear "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The points are not collinear, we can continue\n"
     ]
    }
   ],
   "source": [
    "# Test of non-collinearity\n",
    "v1 = P2 - P1\n",
    "v2 = P3 - P1\n",
    "if torch.norm(torch.cross(v1,v2, dim=0))==0 :\n",
    "    print('Problem: the points must not be collinear')\n",
    "else:\n",
    "    print('The points are not collinear, we can continue')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Creation of an orthonormal frame from f1, f2, f3 (the features vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculation of vectors of the base τ = (C,tx,ty,tz)\n",
    "tx = f1     \n",
    "print(\"tx = \", tx)\n",
    "print(tx.shape)  # (3,)\n",
    "tz = torch.cross(f1,f2)/torch.norm(torch.cross(f1,f2))\n",
    "print(\"tz = \", tz)\n",
    "ty = torch.cross(tz,tx)\n",
    "print(\"ty = \", ty)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display for the verification of non-collinearity of the 3 vectors "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "print(\"tx =\", tx)\n",
    "print(\"ty =\", ty)\n",
    "print(\"tz =\", tz)\n",
    "\n",
    "print(\"\\nVérification orthogonalité :\")\n",
    "print(\"tx · ty =\", np.dot(tx, ty))\n",
    "print(\"tx · tz =\", np.dot(tx, tz))\n",
    "print(\"ty · tz =\", np.dot(ty, tz))\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "origin = np.zeros(3)\n",
    "\n",
    "ax.quiver(*origin, *tx, color='r', label='tx')\n",
    "ax.quiver(*origin, *ty, color='g', label='ty')\n",
    "ax.quiver(*origin, *tz, color='b', label='tz')\n",
    "\n",
    "ax.set_xlim([-1, 1])\n",
    "ax.set_ylim([-1, 1])\n",
    "ax.set_zlim([-1, 1])\n",
    "\n",
    "ax.set_xlabel('X')\n",
    "ax.set_ylabel('Y')\n",
    "ax.set_zlabel('Z')\n",
    "ax.set_title('Base τ (tx, ty, tz)')\n",
    "ax.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. (bis) Creation of a transformation matrix T and expression of the f3 vector in this frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tx = torch.reshape(tx,(1,3))   # (1*3)\n",
    "ty = torch.reshape(ty,(1,3))\n",
    "tz = torch.reshape(tz,(1,3))\n",
    "\n",
    "# Computation of the matrix T and the feature vector f3\n",
    "T = torch.cat((tx,ty,tz),dim = 0) # (3*3)\n",
    "f3_T = torch.tensordot(T,f3, dims=1) # (3,)\n",
    "\n",
    "print(\"tx = \\n\", tx)\n",
    "print(tx.shape)  # (1*3)\n",
    "print(\"ty = \\n\", ty)\n",
    "print(\"tz = \\n\", tz)\n",
    "print(\"f3_T = \\n\", f3_T)\n",
    "print(f3_T.shape)  # (3,)\n",
    "print(\"T = \\n\", T)\n",
    "print(T.shape)  # (3,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sing of the z-coordinate in f3_T give us the sign of teta, that we will need after "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f3_T_positif = False\n",
    "\n",
    "# Having teta in [ 0, pi ] \n",
    "if f3_T[2] > 0 :\n",
    "    f3_T_positif = True\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Change of frame is performed on the 3D points side, and the transformation matrix N is defined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculation of vectors of the base η = (P1,nx,ny,nz)\n",
    "nx = (P2 - P1)/torch.norm(P2 - P1)      #(3,)\n",
    "nz = torch.cross(nx,P3-P1)/torch.norm(torch.cross(nx,P3-P1), dim=0)  \n",
    "ny = torch.cross(nz,nx)\n",
    "print(\"nx = \", nx)\n",
    "print(nx.shape)  # (3,)\n",
    "print(\"ny = \", ny)\n",
    "print(\"nz = \", nz)\n",
    "\n",
    "# Reshape the vectors to (1,3) for concatenation\n",
    "nx = torch.reshape(nx,(1,3))  # (1,3)\n",
    "ny = torch.reshape(ny,(1,3))\n",
    "nz = torch.reshape(nz,(1,3))\n",
    "print(\"nx = \\n\", nx)\n",
    "print(nx.shape)  # (1*3)\n",
    "print(\"ny = \\n\", ny)\n",
    "print(\"nz = \\n\", nz)\n",
    "\n",
    "# Computation of the matrix N and the world point P3\n",
    "N = torch.cat((nx,ny,nz),dim = 0) # (3*3) T's equivalent in the world coordinate system\n",
    "\n",
    "P3_n = torch.tensordot(N,P3-P1, dims=1) # (3,)\n",
    "\n",
    "print(\"N = \\n\", N)\n",
    "print(N.shape)  # (3,3)\n",
    "print(\"P3_n = \\n\", P3_n)\n",
    "print(P3_n.shape)  # (3,)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Definition of the variables for the following steps "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computation of phi1 et phi2 with 0=x, 1=y, 2=z\n",
    "phi1 = f3_T[0]/f3_T[2]\n",
    "phi2 = f3_T[1]/f3_T[2]\n",
    "print(\"phi1 = \", phi1)\n",
    "print(\"phi2 = \", phi2)\n",
    "\n",
    "# Extraction of p1 and p2 from P3_eta\n",
    "p1 = P3_n[0] #x\n",
    "p2 = P3_n[1] #y\n",
    "print(\"p1 = \", p1)\n",
    "print(\"p2 = \", p2)\n",
    "\n",
    "# Computation of d12\n",
    "d12 = torch.norm(P2-P1)\n",
    "print(\"d12 = \", d12)\n",
    "\n",
    "# Computation of b = cot(beta)\n",
    "cosBeta = torch.dot(f1,f2)/(torch.norm(f1)*torch.norm(f2)) \n",
    "print(\"cosBeta = \", cosBeta)  \n",
    "b = torch.sqrt(1/(1-cosBeta**2)-1)\n",
    "\n",
    "if cosBeta < 0 :\n",
    "    b = -b\n",
    "print(\"b = \", b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Calculation of the coefficients of the polynomial "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a4 = - phi2**2 * p2**4 - phi1**2 * p2**4 - p2**4\n",
    "a3 = 2 * p2**3 * d12 * b + 2 * phi2**2 * p2**3 * d12 * b - 2 * phi1 * phi2 * p2**3 * d12\n",
    "a2 = - phi2**2 * p1**2 * p2**2 - phi2**2 * p2**2 * d12**2 * b**2 - phi2**2 * p2**2 * d12**2 + phi2**2 * p2**4 + phi1**2 * p2 **4 + 2 * p1 * p2**2 * d12 + 2 * phi1 * phi2 * p1 * p2**2 * d12 * b - phi1**2 * p1**2 * p2**2 + 2 * phi2**2 * p1 * p2**2 * d12 - p2**2 * d12**2 * b**2 - 2 * p1**2 * p2**2\n",
    "a1 = 2 * p1**2 * p2 * d12 * b + 2 * phi1 * phi2 * p2**3 * d12 - 2 * phi2**2 * p2**3 * d12 * b - 2 * p1 * p2 * d12**2 * b\n",
    "a0 = - 2 * phi1 * phi2 * p1 * p2**2 * d12 * b + phi2**2 * p2**2 * d12**2 + 2 * p1**3 * d12 - p1**2 * d12**2 + phi2**2 * p1**2 * p2**2 - p1**4 - 2 * phi2**2 * p1 * p2**2 * d12 + phi1**2 * p1**2 * p2**2 + phi2**2 * p2**2 * d12**2 * b**2\n",
    "\n",
    "print(\"a4 = \", a4)\n",
    "print(\"a3 = \", a3)\n",
    "print(\"a2 = \", a2)\n",
    "print(\"a1 = \", a1)\n",
    "print(\"a0 = \", a0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. Recovery of the polynomial roots cos (teta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computation of the roots\n",
    "roots = polynomial_root_calculation_4th_degree_ferrari(torch.tensor([a0,a1,a2,a3,a4])) # (4,)\n",
    "\n",
    "print(\"roots = \\n\", roots)  # list of tensor (for complex numbers)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. For each solution : computation of the camera position and rotation matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each solution of the polynomial\n",
    "for i in range(4):\n",
    "  #if np.isclose(np.imag(roots[i]),0) : # if real solution \n",
    "\n",
    "    # Computation of trigonometrics forms\n",
    "    cos_teta = torch.tensor(roots[i][0])# real part of the root \n",
    "    sin_teta = torch.sqrt(1-cos_teta**2)\n",
    "\n",
    "    cot_alpha = ((phi1/phi2)*p1 + cos_teta*p2 -d12*b )/ ((phi1/phi2)*cos_teta* p2 - p1 + d12)\n",
    "\n",
    "    sin_alpha = torch.sqrt(1/(cot_alpha**2+1))\n",
    "    cos_alpha= torch.sqrt(1-sin_alpha**2)\n",
    "\n",
    "    if cot_alpha < 0 :\n",
    "      cos_alpha = -cos_alpha\n",
    "\n",
    "    # Computation of the intermediate rotation's matrixs\n",
    "    C_estimate = torch.tensor([d12*cos_alpha*(sin_alpha*b + cos_alpha), d12*sin_alpha*cos_teta*(sin_alpha*b+cos_alpha), d12*sin_alpha*sin_teta*(sin_alpha*b+cos_alpha)]) # (3,)\n",
    "    print(\"C_estimate = \\n\", C_estimate)\n",
    "    print(C_estimate.shape)  # (3,)\n",
    "    Q = torch.tensor([[-cos_alpha, -sin_alpha*cos_teta, -sin_alpha*sin_teta], [sin_alpha, -cos_alpha*cos_teta, -cos_alpha*sin_teta], [0, -sin_teta, cos_teta]])    # (3*3)\n",
    "    print(\"Q = \\n\", Q)\n",
    "    print(Q.shape)  # (3,3)\n",
    "    # Computation of the absolute camera center\n",
    "  \n",
    "    C_estimate = P1 + torch.tensordot(torch.transpose(N, 0,1), C_estimate, dims=1) # (3,)\n",
    "    print(\"C_estimate = \\n\", C_estimate) \n",
    "    print(C_estimate.shape)  # (3,)\n",
    "    C_estimate = torch.reshape(C_estimate, (3,1))  # Reshape to (3,1) for consistency\n",
    "    print(\"C_estimate = \\n\", C_estimate)  # (3,1)\n",
    "    print(\"C_estimate.shape = \", C_estimate.shape)  # (3,1)\n",
    "\n",
    "    # Computation of the orientation matrix\n",
    "    R_estimate = torch.tensordot(torch.tensordot(torch.transpose(N,0,1),torch.transpose(Q, 0,1), dims=1),T,dims=1)   # (3*3)\n",
    "    print(\"R_estimate = \\n\", R_estimate)\n",
    "    print(R_estimate.shape)  # (3,3)\n",
    "    \n",
    "    # Adding C and R to the solutions\n",
    "    solutions[i,:,:1]= C_estimate\n",
    "    solutions[i,:,1:] = R_estimate\n",
    "\n",
    "print(\"solutions = \\n\", solutions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"solutions = \\n\", solutions)\n",
    "print(solutions.shape)  # (4,3,4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11. Reprojection of points in 2D from the newly estimated matrices to verify the estimation error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def projection3D2D(point3D,C,R,A) :\n",
    "  # 3D point = [ Xw, Yw, Zw ]'   (1*3)\n",
    "  # T : camera translation matrix : (3*1)\n",
    "  # R : camera rotation matrix : (3*3)\n",
    "  # A : intraseca matrix of the camera : (3*3)\n",
    "  # Output : return the coordonates of the point in 2D \n",
    "\n",
    "  PI = torch.cat((torch.eye(3, dtype=torch.float64),torch.zeros((3,1), dtype=torch.float64)),dim=1)  # (3*4)\n",
    "\n",
    "  Rt = torch.cat((R,C),dim=1)               # (3*4)\n",
    "  Rt = torch.cat((Rt,torch.tensor([[0,0,0,1]], dtype=torch.float64)),dim=0)   # (4*4)\n",
    "\n",
    "  point3D_bis = torch.cat((torch.reshape(point3D,(3,1)),torch.tensor([[1]],dtype=torch.float64)),dim=0)   #(4*1)\n",
    "  \n",
    "  point2D = torch.tensordot(torch.tensordot(torch.tensordot(A,PI,dims=1),Rt,dims=1),point3D_bis,dims=1)  # 2D point = [u, v, w] (3*1)\n",
    "  point2D = point2D / point2D[2]        # 2D point = [u, v, 1] (3*1)\n",
    "  return point2D[:2]\n",
    "\n",
    "\n",
    "C_transpose = torch.transpose(C, 0, 1)  # (3*1) -> (1*3)\n",
    "\n",
    "p1 = projection3D2D(P1,C_transpose,R,A)\n",
    "print(\"p1 = \", p1)\n",
    "print(p1.shape)  # (2,1)\n",
    "p2 = projection3D2D(points3D[1],C_transpose,R,A)\n",
    "print(\"p2 = \", p2)\n",
    "p3 = projection3D2D(points3D[2],C_transpose,R,A)\n",
    "print(\"p3 = \", p3)\n",
    "p4 = projection3D2D(P4,C_transpose,R,A)\n",
    "print(\"p4 = \", p4)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12. Calculation of errors = distance between the 2D points estimated from the found rotation and position matrices and the 2D points from the initial matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance(pt, pt_estimation):\n",
    "    erreur = torch.tensor(0, dtype=torch.float64)  # Initialize error as a tensor\n",
    "    for i in range(len(pt)): \n",
    "      erreur = erreur + torch.tensor((pt[i] - pt_estimation[i])**2, dtype=torch.float64)  # Ensure each term is a tensor\n",
    "      #erreur += (pt[i] - pt_estimation[i])**2\n",
    "    return torch.sqrt(erreur)\n",
    "\n",
    "\n",
    "\n",
    "def affichage_erreur(solutions,points2D,points3D,A) : \n",
    "   # Compute the error of estimation for each points after the P3P algorithm \n",
    "\n",
    "   # solutions : solution matrix returned by P3P (4*3*4)\n",
    "   # points 3D : 4 pts 3D used for P3P \n",
    "   # points 2D : 4 pts 2D used for P3P (image of the 3D points)\n",
    "   \n",
    "   P1 = points3D[0]\n",
    "   P2 = points3D[1]\n",
    "   P3 = points3D[2]\n",
    "   P4 = points3D[3]\n",
    "\n",
    "   erreurs = []\n",
    "   nb_sol = 0\n",
    "\n",
    "   for i in range(len(solutions)) : \n",
    "      R = solutions[i,:,1:] \n",
    "      C = solutions[i,:,:1]\n",
    "\n",
    "      if not torch.all(R==torch.zeros((3,3))) : \n",
    "        nb_sol += 1 \n",
    "        print(\"------------ Solution n° : \",nb_sol,\"----------------\")\n",
    "        print(\"R = \\n\",R,)\n",
    "        print(\"T = \\n\",C,)\n",
    "\n",
    "        p1_P3P = torch.reshape(projection3D2D(P1,C,R,A),(1,2))\n",
    "        p2_P3P = torch.reshape(projection3D2D(P2,C,R,A),(1,2))\n",
    "        p3_P3P = torch.reshape(projection3D2D(P3,C,R,A),(1,2))\n",
    "        p4_P3P = torch.reshape(projection3D2D(P4,C,R,A),(1,2))\n",
    "        pt_2D_P3P = torch.cat((p1_P3P,p2_P3P,p3_P3P,p4_P3P),dim=0)    # (4,2)\n",
    "\n",
    "        erreurs.append([0])\n",
    "        for j in range(len(points2D)):\n",
    "            erreur_pt = distance(points2D[j],pt_2D_P3P[j])\n",
    "            erreurs[i]+=erreur_pt\n",
    "        \n",
    "   indice_min = 0\n",
    "   min = erreurs[0]\n",
    "   for i in range(1,len(erreurs)) :\n",
    "    if erreurs[i]<min :\n",
    "      min = erreurs[i]\n",
    "      indice_min = i\n",
    "\n",
    "   R_opti = solutions[indice_min,:,1:] \n",
    "   C_opti = solutions[indice_min,:,:1]\n",
    "   print(\"\\n------------ Best solution : ----------------\")\n",
    "   print(\"Solution n° :\",indice_min+1,\"\\n\")\n",
    "   print(\"R estimé = \\n\", R_opti,\"\\n\")\n",
    "   print(\"T estimé = \\n\", C_opti, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "affichage_erreur(solutions, [p1, p2, p3, p4], [P1,P2,P3, P4], A)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
