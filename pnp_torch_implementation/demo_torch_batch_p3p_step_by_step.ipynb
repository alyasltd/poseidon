{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import torch\n",
    "\n",
    "batch_size = 5 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At first we have : \n",
    "- camera's parameters -> A (focal, center) \n",
    "- rotation matrix  -> R \n",
    "- position matrix -> C \n",
    "- 3D points position ->  P1 P2 P3 (and P4 to determinate the best solution after P3P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A = \n",
      " tensor([[800.,   0., 320.],\n",
      "        [  0., 800., 240.],\n",
      "        [  0.,   0.,   1.]], dtype=torch.float64)\n",
      "torch.Size([3, 3])\n",
      "A_batch = \n",
      " tensor([[[800.,   0., 320.],\n",
      "         [  0., 800., 240.],\n",
      "         [  0.,   0.,   1.]],\n",
      "\n",
      "        [[800.,   0., 320.],\n",
      "         [  0., 800., 240.],\n",
      "         [  0.,   0.,   1.]],\n",
      "\n",
      "        [[800.,   0., 320.],\n",
      "         [  0., 800., 240.],\n",
      "         [  0.,   0.,   1.]],\n",
      "\n",
      "        [[800.,   0., 320.],\n",
      "         [  0., 800., 240.],\n",
      "         [  0.,   0.,   1.]],\n",
      "\n",
      "        [[800.,   0., 320.],\n",
      "         [  0., 800., 240.],\n",
      "         [  0.,   0.,   1.]]], dtype=torch.float64)\n",
      "torch.Size([5, 3, 3])\n",
      "R = \n",
      " tensor([[ 1.,  0.,  0.],\n",
      "        [ 0., -1.,  0.],\n",
      "        [ 0.,  0., -1.]], dtype=torch.float64)\n",
      "torch.Size([3, 3])\n",
      "R_batch = \n",
      " tensor([[[ 1.,  0.,  0.],\n",
      "         [ 0., -1.,  0.],\n",
      "         [ 0.,  0., -1.]],\n",
      "\n",
      "        [[ 1.,  0.,  0.],\n",
      "         [ 0., -1.,  0.],\n",
      "         [ 0.,  0., -1.]],\n",
      "\n",
      "        [[ 1.,  0.,  0.],\n",
      "         [ 0., -1.,  0.],\n",
      "         [ 0.,  0., -1.]],\n",
      "\n",
      "        [[ 1.,  0.,  0.],\n",
      "         [ 0., -1.,  0.],\n",
      "         [ 0.,  0., -1.]],\n",
      "\n",
      "        [[ 1.,  0.,  0.],\n",
      "         [ 0., -1.,  0.],\n",
      "         [ 0.,  0., -1.]]], dtype=torch.float64)\n",
      "torch.Size([5, 3, 3])\n",
      "C = \n",
      " tensor([[0., 0., 6.]], dtype=torch.float64)\n",
      "torch.Size([1, 3])\n",
      "C_batch = \n",
      " tensor([[0., 0., 6.],\n",
      "        [0., 0., 6.],\n",
      "        [0., 0., 6.],\n",
      "        [0., 0., 6.],\n",
      "        [0., 0., 6.]], dtype=torch.float64)\n",
      "torch.Size([5, 3])\n"
     ]
    }
   ],
   "source": [
    "# This script defines the camera parameters, rotation matrix, and translation matrix.\n",
    "def camera() : \n",
    "  # Definition of the camera parameters\n",
    "  # focal length\n",
    "  fx = 800\n",
    "  fy = 800\n",
    "  # center\n",
    "  cx = 320 \n",
    "  cy = 240\n",
    "\n",
    "  A = torch.tensor([[fx, 0, cx], [0, fy, cy], [0, 0, 1]], dtype=torch.float64) # intraseca matrix of the camera (3*3)\n",
    "  #A = torch.from_numpy(A)  # Convert to a PyTorch tensor\n",
    "  print(\"A = \\n\", A)\n",
    "  print(A.shape)  # (3*3)\n",
    "  A_batch = A.repeat(batch_size,1,1)\n",
    "  print(\"A_batch = \\n\", A_batch)\n",
    "  print(A_batch.shape)  # (batch_size, 3, 3)\n",
    "  return A_batch\n",
    "\n",
    "A = camera() \n",
    "\n",
    "\n",
    "\n",
    "def rotation_matrix() : \n",
    "  # Definition of the rotation matrix of the camera \n",
    "  R = torch.tensor([[1, 0, 0],[0, -1, 0], [0, 0, -1]], dtype=torch.float64)  # (3*3)\n",
    "  #R = torch.from_numpy(R)  # Convert to a PyTorch tensor\n",
    "  print(\"R = \\n\",R)\n",
    "  print(R.shape)  # (3*3)\n",
    "  R_batch = R.repeat(batch_size,1,1)  # Repeat the rotation matrix for each batch\n",
    "  print(\"R_batch = \\n\", R_batch)  \n",
    "  print(R_batch.shape)  # (batch_size, 3, 3)\n",
    "  return R_batch\n",
    "\n",
    "def camera_position() : \n",
    "  # Definition of the translation matrix of the camera (the position)\n",
    "  C = torch.tensor([[0,0,6]], dtype=torch.float64)    # T = [tx,ty,tz]  (1*3)\n",
    "  print(\"C = \\n\",C)\n",
    "  print(C.shape)  # (1*3)\n",
    "\n",
    "  C_batch = C.repeat(batch_size, 1)  # Repeat the translation vector for each batch\n",
    "  print(\"C_batch = \\n\", C_batch)  \n",
    "  print(C_batch.shape)  # (batch_size, 3)\n",
    "\n",
    " \n",
    "  return C_batch\n",
    "\n",
    "R = rotation_matrix()\n",
    "C = camera_position()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "points3D = \n",
      " tensor([[-0.4336,  1.2735,  1.3707],\n",
      "        [-1.4018,  0.2368,  1.2999],\n",
      "        [-1.7486, -0.8187,  0.6125],\n",
      "        [-1.6914,  0.0598, -0.5561]])\n",
      "torch.Size([4, 3])\n",
      "points3D = \n",
      " tensor([[-1.7995,  0.4201,  0.0132],\n",
      "        [ 0.7036, -0.1004, -0.5404],\n",
      "        [-0.8722, -1.1441, -1.6584],\n",
      "        [ 0.7110,  0.3175,  1.5805]])\n",
      "torch.Size([4, 3])\n",
      "points3D = \n",
      " tensor([[ 1.5382,  0.3528,  0.0984],\n",
      "        [ 0.1061, -0.8137, -1.8533],\n",
      "        [ 0.5140, -0.8249,  1.0075],\n",
      "        [-0.8183,  0.6201, -0.1573]])\n",
      "torch.Size([4, 3])\n",
      "points3D = \n",
      " tensor([[-0.5543,  0.2068,  0.0388],\n",
      "        [ 0.7492,  1.6988,  0.9027],\n",
      "        [ 0.1988, -1.0855, -0.3351],\n",
      "        [-0.0565,  1.2946,  1.3896]])\n",
      "torch.Size([4, 3])\n",
      "points3D = \n",
      " tensor([[-0.5095, -1.5698,  1.3310],\n",
      "        [-0.7759,  0.8086, -1.0455],\n",
      "        [ 1.0033, -0.2136,  1.8101],\n",
      "        [ 1.9835, -1.3274, -0.2711]])\n",
      "torch.Size([4, 3])\n",
      "points3D_batch = \n",
      " tensor([[[-0.4336,  1.2735,  1.3707],\n",
      "         [-1.4018,  0.2368,  1.2999],\n",
      "         [-1.7486, -0.8187,  0.6125],\n",
      "         [-1.6914,  0.0598, -0.5561]],\n",
      "\n",
      "        [[-1.7995,  0.4201,  0.0132],\n",
      "         [ 0.7036, -0.1004, -0.5404],\n",
      "         [-0.8722, -1.1441, -1.6584],\n",
      "         [ 0.7110,  0.3175,  1.5805]],\n",
      "\n",
      "        [[ 1.5382,  0.3528,  0.0984],\n",
      "         [ 0.1061, -0.8137, -1.8533],\n",
      "         [ 0.5140, -0.8249,  1.0075],\n",
      "         [-0.8183,  0.6201, -0.1573]],\n",
      "\n",
      "        [[-0.5543,  0.2068,  0.0388],\n",
      "         [ 0.7492,  1.6988,  0.9027],\n",
      "         [ 0.1988, -1.0855, -0.3351],\n",
      "         [-0.0565,  1.2946,  1.3896]],\n",
      "\n",
      "        [[-0.5095, -1.5698,  1.3310],\n",
      "         [-0.7759,  0.8086, -1.0455],\n",
      "         [ 1.0033, -0.2136,  1.8101],\n",
      "         [ 1.9835, -1.3274, -0.2711]]])\n",
      "torch.Size([5, 4, 3])\n",
      "P1 = \n",
      " tensor([[-0.4336,  1.2735,  1.3707],\n",
      "        [-1.7995,  0.4201,  0.0132],\n",
      "        [ 1.5382,  0.3528,  0.0984],\n",
      "        [-0.5543,  0.2068,  0.0388],\n",
      "        [-0.5095, -1.5698,  1.3310]])\n",
      "torch.Size([5, 3])\n"
     ]
    }
   ],
   "source": [
    "# Definition of 3D points in the world coordinate system\n",
    "def point3Daleatoire(x) :\n",
    "  # Generation of one random points in 3D space \n",
    "  return torch.tensor([[np.random.uniform(-x,x),np.random.uniform(-x,x),np.random.uniform(-x,x)]])\n",
    "\n",
    "def pts_3D_4pts():\n",
    "  # Generate randomly 4 3D points\n",
    "  # Output : tensor which concatenate the 4 points = [ P1, P2, P3, P4 ] \n",
    "\n",
    "  P1 = point3Daleatoire(2)     # (1*3) -> pour P3P\n",
    "  P2 = point3Daleatoire(2)\n",
    "  P3 = point3Daleatoire(2)\n",
    "  P4 = point3Daleatoire(2)\n",
    "  \n",
    "  points3D = torch.cat((P1,P2,P3,P4),dim=0);     # (LIGNES 4* COLONNES 3) - xyz\n",
    "  print(\"points3D = \\n\", points3D)\n",
    "  print(points3D.shape)  # (4*3)\n",
    "\n",
    "  \n",
    "  return points3D\n",
    "\n",
    "def pts_3D_4pts_batch():\n",
    "  # Generate randomly 4 3D points for each batch\n",
    "  # Output : array which concatenate the 4 points = [ P1, P2, P3, P4 ] for each batch\n",
    "\n",
    "  # Generate a batch of random points in 3D space\n",
    "  # Each point is generated independently for each batch\n",
    "\n",
    "  points3D_batch = torch.stack([pts_3D_4pts() for i in range(batch_size)])  # (batch_size, 4, 3)\n",
    "  print(\"points3D_batch = \\n\", points3D_batch)\n",
    "  print(points3D_batch.shape)  # (batch_size, 4, 3)\n",
    "  return points3D_batch\n",
    "\n",
    "points3D_batch = pts_3D_4pts_batch()  # Generate the batch of 3D points\n",
    "'''\n",
    "P1 = torch.tensor([0.7161, 0.5431, 1.7807], dtype=torch.float64)    # (3,)\n",
    "P2 = torch.tensor([-1.1643, 0.8371, -1.0551], dtype=torch.float64)\n",
    "P3 = torch.tensor([-1.5224, 0.4292, -0.1994], dtype=torch.float64)\n",
    "P4 = torch.tensor([-1.5224, 0.4292, -0.1994], dtype=torch.float64) \n",
    "'''\n",
    "P1 = points3D_batch[:, 0, :]  # Extract P1 for each batch\n",
    "P2 = points3D_batch[:, 1, :]  # Extract P2 for each batch\n",
    "P3 = points3D_batch[:, 2, :]  # Extract P3 for each batch\n",
    "P4 = points3D_batch[:, 3, :]  # Extract P4 for each batch\n",
    "\n",
    "print(\"P1 = \\n\", P1)\n",
    "print(P1.shape)  # (batch_size, 3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create the 3 direction features vectors f1, f2, f3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "points3D = \n",
      " [tensor([[-0.4336,  1.2735,  1.3707],\n",
      "        [-1.7995,  0.4201,  0.0132],\n",
      "        [ 1.5382,  0.3528,  0.0984],\n",
      "        [-0.5543,  0.2068,  0.0388],\n",
      "        [-0.5095, -1.5698,  1.3310]]), tensor([[-1.4018,  0.2368,  1.2999],\n",
      "        [ 0.7036, -0.1004, -0.5404],\n",
      "        [ 0.1061, -0.8137, -1.8533],\n",
      "        [ 0.7492,  1.6988,  0.9027],\n",
      "        [-0.7759,  0.8086, -1.0455]]), tensor([[-1.7486, -0.8187,  0.6125],\n",
      "        [-0.8722, -1.1441, -1.6584],\n",
      "        [ 0.5140, -0.8249,  1.0075],\n",
      "        [ 0.1988, -1.0855, -0.3351],\n",
      "        [ 1.0033, -0.2136,  1.8101]])]\n",
      "P1 = \n",
      " tensor([[[-0.4336],\n",
      "         [ 1.2735],\n",
      "         [ 1.3707]],\n",
      "\n",
      "        [[-1.7995],\n",
      "         [ 0.4201],\n",
      "         [ 0.0132]],\n",
      "\n",
      "        [[ 1.5382],\n",
      "         [ 0.3528],\n",
      "         [ 0.0984]],\n",
      "\n",
      "        [[-0.5543],\n",
      "         [ 0.2068],\n",
      "         [ 0.0388]],\n",
      "\n",
      "        [[-0.5095],\n",
      "         [-1.5698],\n",
      "         [ 1.3310]]])\n",
      "torch.Size([5, 3, 1])\n",
      "C = \n",
      " tensor([[[0.],\n",
      "         [0.],\n",
      "         [6.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [6.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [6.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [6.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [6.]]], dtype=torch.float64)\n",
      "torch.Size([5, 3, 1])\n",
      "v1 = \n",
      " tensor([[[-0.4336],\n",
      "         [-1.2735],\n",
      "         [ 4.6293]],\n",
      "\n",
      "        [[-1.7995],\n",
      "         [-0.4201],\n",
      "         [ 5.9868]],\n",
      "\n",
      "        [[ 1.5382],\n",
      "         [-0.3528],\n",
      "         [ 5.9016]],\n",
      "\n",
      "        [[-0.5543],\n",
      "         [-0.2068],\n",
      "         [ 5.9612]],\n",
      "\n",
      "        [[-0.5095],\n",
      "         [ 1.5698],\n",
      "         [ 4.6690]]], dtype=torch.float64)\n",
      "torch.Size([5, 3, 1])\n",
      "f1 = \n",
      " tensor([[[-0.0899],\n",
      "         [-0.2642],\n",
      "         [ 0.9603]],\n",
      "\n",
      "        [[-0.2872],\n",
      "         [-0.0671],\n",
      "         [ 0.9555]],\n",
      "\n",
      "        [[ 0.2518],\n",
      "         [-0.0578],\n",
      "         [ 0.9661]],\n",
      "\n",
      "        [[-0.0925],\n",
      "         [-0.0345],\n",
      "         [ 0.9951]],\n",
      "\n",
      "        [[-0.1029],\n",
      "         [ 0.3170],\n",
      "         [ 0.9428]]], dtype=torch.float64)\n",
      "torch.Size([5, 3, 1])\n",
      "f1 :  torch.Size([5, 1, 3])\n",
      "features vectors = \n",
      " tensor([[[-0.0899, -0.2642,  0.9603],\n",
      "         [-0.2855, -0.0482,  0.9572],\n",
      "         [-0.3055,  0.1431,  0.9414]],\n",
      "\n",
      "        [[-0.2872, -0.0671,  0.9555],\n",
      "         [ 0.1069,  0.0153,  0.9941],\n",
      "         [-0.1119,  0.1468,  0.9828]],\n",
      "\n",
      "        [[ 0.2518, -0.0578,  0.9661],\n",
      "         [ 0.0134,  0.1030,  0.9946],\n",
      "         [ 0.1011,  0.1622,  0.9816]],\n",
      "\n",
      "        [[-0.0925, -0.0345,  0.9951],\n",
      "         [ 0.1381, -0.3131,  0.9396],\n",
      "         [ 0.0309,  0.1688,  0.9852]],\n",
      "\n",
      "        [[-0.1029,  0.3170,  0.9428],\n",
      "         [-0.1088, -0.1133,  0.9876],\n",
      "         [ 0.2326,  0.0495,  0.9713]]], dtype=torch.float64)\n",
      "torch.Size([5, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "def features_vectors(points3D,C, R,batch_size) :\n",
    "    '''\n",
    "    This function computes the features vectors for P3P algorithm.\n",
    "    args:\n",
    "    points3D : array with the 4 3D points = [ P1, P2, P3, P4 ] (4*3) \n",
    "    but we only use the first three points for P3P\n",
    "    C: camera position matrix : (3*1)\n",
    "    returns:\n",
    "    featuresVect : array with the features vectors (9*1)\n",
    "    '''\n",
    "    P1 = torch.reshape(points3D[0], (batch_size,3,1))  # Reshape to (3,1) for easier calculations\n",
    "    print(\"P1 = \\n\", P1)  # Print P1 to check the values\n",
    "    print(P1.shape)  # (batch_size, 3, 1)\n",
    "    P2 = torch.reshape(points3D[1], (batch_size,3,1))\n",
    "    P3 = torch.reshape(points3D[2], (batch_size,3,1))\n",
    "\n",
    "    C = torch.reshape(C, (batch_size,3,1))  # Reshape C to (3,1) for easier calculations\n",
    "    print(\"C = \\n\", C)  # Print C to check the values\n",
    "    print(C.shape)  # (batch_size, 3, 1)\n",
    "\n",
    "    v1 = torch.matmul(R,(P1 - C))  # Calculate the vector from camera to P1\n",
    "    print(\"v1 = \\n\", v1)  # Print v1 to check the values\n",
    "    print(v1.shape)  # (batch_size, 3, 1)\n",
    "    v2 = torch.matmul(R,(P2 - C))  # Calculate the vector from camera to P2\n",
    "    v3 = torch.matmul(R,(P3 - C))  # Calculate the vector from camera to P3\n",
    "\n",
    "    f1 = v1 / torch.norm(v1,dim=1, keepdim=True)  # Normalize the vector v1\n",
    "    f2 = v2 / torch.norm(v2,dim=1, keepdim=True)  # Normalize the vector v2\n",
    "    f3 = v3 / torch.norm(v3,dim=1, keepdim=True)  # Normalize the vector v3\n",
    "\n",
    "    print(\"f1 = \\n\", f1)  # Print f1 to check the values\n",
    "    print(f1.shape)  # (batch_size, 3, 1)\n",
    "\n",
    "    f1 = torch.reshape(f1, (batch_size,1,3))  # Reshape to (3,1)\n",
    "    print(\"f1 : \",f1.shape) # (batch_size,1,3)\n",
    "    f2 = torch.reshape(f2, (batch_size,1,3))\n",
    "    f3 = torch.reshape(f3, (batch_size,1,3))\n",
    "\n",
    "    featuresVect = torch.cat((f1,f2,f3),dim=1)\n",
    "    print(\"features vectors = \\n\",featuresVect)\n",
    "    print(featuresVect.shape)  # (batch_size, 3, 3)\n",
    "\n",
    "    return featuresVect # Return the features vectors need in P3P\n",
    "\n",
    "\n",
    "points3D = [P1, P2, P3]  # We define the points3D with the first three points\n",
    "print(\"points3D = \\n\", points3D)  # Print the points3D to check the values  / List len = 3 \n",
    "\n",
    "\n",
    "featuresVect = features_vectors(points3D, C, R,batch_size)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly we need the functions to resolve the polynomial roots. - for test go to test resolution polynome "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from complex_utils import *\n",
    "\n",
    "def polynomial_root_calculation_3rd_degree(a, b, c, d):\n",
    "    '''# Convert to complex tensors\n",
    "    a = torch.tensor(a, dtype=torch.complex64)\n",
    "    b = torch.tensor(b, dtype=torch.complex64)\n",
    "    c = torch.tensor(c, dtype=torch.complex64)\n",
    "    d = torch.tensor(d, dtype=torch.complex64)'''\n",
    "\n",
    "    # Discriminant terms\n",
    "    p = (3 * a * c - b**2) / (3 * a**2)\n",
    "    q = (2 * b**3 - 9 * a * b * c + 27 * a**2 * d) / (27 * a**3)\n",
    "    delta = -4 * p**3 - 27 * q**2\n",
    "    roots = []\n",
    "\n",
    "    j_ = torch.tensor([-0.5, torch.sqrt(torch.tensor(3))/2])  # cube root of unity\n",
    "\n",
    "    k = torch.tensor([0,1,2])\n",
    "\n",
    "    delta_sur_27 = -delta / 27          # reéls\n",
    "\n",
    "    sqrt_term = sqrt(delta_sur_27)  # Use the sqrt function defined above\n",
    "    u_k = product_of_2_complex_numbers(complex_number_power_k(j_,k), sqrt_3(torch.tensor([0.5*(-q+sqrt_term[0]),sqrt_term[1]])) )# because q real \n",
    "    v_k = product_of_2_complex_numbers(complex_number_power_k(j_,-k), sqrt_3(torch.tensor([0.5*(-q-sqrt_term[0]),-0.5*sqrt_term[1]])))\n",
    "\n",
    "    root = addition(addition(u_k, v_k), torch.tensor([-b/(3*a),0]) ) \n",
    "    roots.append(root)\n",
    "\n",
    "    return torch.stack(roots)\n",
    "\n",
    "def polynomial_root_calculation_4th_degree_ferrari(a): # Ferrari's Method\n",
    "    # Solving a polynomial of 4th degree\n",
    "\n",
    "    # Input : array 5*1 with the 5 coefficiants of the polynomial \n",
    "    # Output : roots of the polynomial a[4]*x^4 + a[3]*x^3 + a[2]*x^2 + a[1]*x + a[0]   -> array : [x1,x2,x3,x4]  (4*1)\n",
    "\n",
    "    if a.numel() != 5 :\n",
    "      print(\"Expeted 5 coefficiants for a 4th order polynomial\")\n",
    "      return\n",
    "\n",
    "    a0, a1, a2, a3, a4 = a      # float\n",
    "\n",
    "    # Reduce the quartic equation to the form : x^4 + a*x^3 + b*x^2 + c*x + d = 0\n",
    "    a = a3/a4           # float \n",
    "    b = a2/a4\n",
    "    c = a1/a4\n",
    "    d = a0/a4\n",
    "\n",
    "    # Computation of the coefficients of the Ferrari's Method\n",
    "    S = a/4\n",
    "    b0 = d - c*S + b* S**2 - 3* S**4\n",
    "    b1 = c - 2*b*S + 8*S**3\n",
    "    b2 = b - 6 * S**2\n",
    "\n",
    "\n",
    "    # Solve the cubic equation m^3 + b2*m^2 + (b2^2/4  - b0)*m - b1^2/8 = 0\n",
    "    x_cube = polynomial_root_calculation_3rd_degree(1,b2,(b2**2)/4-b0,(-b1**2)/8)\n",
    "    \n",
    "\n",
    "    # Find a real and positive solution\n",
    "    condition = (torch.isclose(x_cube[:,1],torch.tensor(0.0,dtype=torch.float64),atol=1e-7)) & (x_cube[:,0] > 0) \n",
    "    condition_respected = x_cube[condition]  # Get the indices of the roots that respect the condition\n",
    "\n",
    "    print(\"indices_respect_condition = \\n\", condition_respected)  # Print the indices of the roots that respect the condition\n",
    "    alpha_0_nul = condition_respected.shape[0] == 0\n",
    "\n",
    "    if not alpha_0_nul : \n",
    "       alpha_0 = condition_respected[-1]\n",
    "\n",
    "\n",
    "    if alpha_0_nul == False :   # case where we found a real and positive solution so alpha_0_imag = 0 \n",
    "        alpha0_div_2 = product_complex_real(alpha_0,0.5)\n",
    "        sqrt_alpha = sqrt(alpha0_div_2[0])\n",
    "        term = addition_complex_real(- alpha0_div_2 ,-b2 / 2)\n",
    "        denom = 2 * torch.sqrt(2 * alpha_0)\n",
    "        \n",
    "       \n",
    "        frac = division_2_complex_numbers(torch.tensor([b1, 0.0]), denom)  # b1 is real, so we can use a tensor with 0 imaginary part\n",
    "\n",
    "        x1 = addition_complex_real(sqrt_alpha ,- S) + sqrt_complex(addition(term,-frac))\n",
    "        x2 = addition_complex_real(sqrt_alpha, - S) - sqrt_complex(addition(term,-frac))\n",
    "        x3 = addition_complex_real(-sqrt_alpha, - S) + sqrt_complex(addition(term,frac))\n",
    "        x4 = addition_complex_real(-sqrt_alpha,- S) - sqrt_complex(addition(term,frac))\n",
    "    \n",
    "    else:\n",
    "\n",
    "        sqrt_inner1 = sqrt((b2**2) / 4 - b0)        # complex \n",
    "        x1 = addition_complex_real(sqrt_complex(addition_complex_real(sqrt_inner1,-b2 / 2)),-S)\n",
    "        x2 = addition_complex_real(- sqrt_complex(addition_complex_real(sqrt_inner1,-b2 / 2)),-S)\n",
    "        x3 = addition_complex_real(sqrt_complex(addition_complex_real(- sqrt_inner1,-b2 / 2 )),-S)\n",
    "        x4 = addition_complex_real(- sqrt_complex(addition_complex_real(- sqrt_inner1,-b2 / 2 )),-S)\n",
    "\n",
    "    return torch.tensor([x1, x2, x3, x4])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have all the variables needed for the p3p so we start"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Storage of points : already done "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P1 = \n",
      " tensor([[-0.4336,  1.2735,  1.3707],\n",
      "        [-1.7995,  0.4201,  0.0132],\n",
      "        [ 1.5382,  0.3528,  0.0984],\n",
      "        [-0.5543,  0.2068,  0.0388],\n",
      "        [-0.5095, -1.5698,  1.3310]])\n",
      "P2 = \n",
      " tensor([[-1.4018,  0.2368,  1.2999],\n",
      "        [ 0.7036, -0.1004, -0.5404],\n",
      "        [ 0.1061, -0.8137, -1.8533],\n",
      "        [ 0.7492,  1.6988,  0.9027],\n",
      "        [-0.7759,  0.8086, -1.0455]])\n",
      "P3 = \n",
      " tensor([[-1.7486, -0.8187,  0.6125],\n",
      "        [-0.8722, -1.1441, -1.6584],\n",
      "        [ 0.5140, -0.8249,  1.0075],\n",
      "        [ 0.1988, -1.0855, -0.3351],\n",
      "        [ 1.0033, -0.2136,  1.8101]])\n"
     ]
    }
   ],
   "source": [
    "print(\"P1 = \\n\", P1)\n",
    "print(\"P2 = \\n\", P2)\n",
    "print(\"P3 = \\n\", P3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Storage of the features vectors : done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 =  tensor([[-0.0899, -0.2642,  0.9603],\n",
      "        [-0.2872, -0.0671,  0.9555],\n",
      "        [ 0.2518, -0.0578,  0.9661],\n",
      "        [-0.0925, -0.0345,  0.9951],\n",
      "        [-0.1029,  0.3170,  0.9428]], dtype=torch.float64)\n",
      "torch.Size([5, 3])\n",
      "f2 =  tensor([[-0.2855, -0.0482,  0.9572],\n",
      "        [ 0.1069,  0.0153,  0.9941],\n",
      "        [ 0.0134,  0.1030,  0.9946],\n",
      "        [ 0.1381, -0.3131,  0.9396],\n",
      "        [-0.1088, -0.1133,  0.9876]], dtype=torch.float64)\n",
      "torch.Size([5, 3])\n",
      "f3 =  tensor([[-0.3055,  0.1431,  0.9414],\n",
      "        [-0.1119,  0.1468,  0.9828],\n",
      "        [ 0.1011,  0.1622,  0.9816],\n",
      "        [ 0.0309,  0.1688,  0.9852],\n",
      "        [ 0.2326,  0.0495,  0.9713]], dtype=torch.float64)\n",
      "torch.Size([5, 3])\n"
     ]
    }
   ],
   "source": [
    "# we got featuresVect and we access the 3 values \n",
    "f1 = featuresVect[:,0,:]  # Access the first feature vector for each batch\n",
    "f2 = featuresVect[:,1,:]\n",
    "f3 = featuresVect[:,2,:]\n",
    "\n",
    "print(\"f1 = \", f1)\n",
    "print(f1.shape)  # (batsh_size,3)\n",
    "print(\"f2 = \", f2)\n",
    "print(f2.shape)  # (batsh_size,3)\n",
    "print(\"f3 = \", f3)\n",
    "print(f3.shape)  # (batsh_size,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Création of a solution variable : maximum 4 solutions  \n",
    "\n",
    "    Matrix (4,3,4)  \n",
    "    Each layer is a solution, for each leayer : first column stres the camera position matrix C (3,1) and the remaining 3 columns store the rotation matrix R (3,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "solutions = \n",
      " tensor([[[[0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0.]]]], dtype=torch.float64)\n",
      "torch.Size([5, 4, 3, 4])\n"
     ]
    }
   ],
   "source": [
    "solutions = torch.zeros((batch_size,4,3,4), dtype=torch.float64)\n",
    "print(\"solutions = \\n\", solutions)\n",
    "print(solutions.shape)  # (4,3,4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Verification that the 3 points given are not collinear "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "v1 = \n",
      " tensor([[-0.9683, -1.0367, -0.0708],\n",
      "        [ 2.5031, -0.5205, -0.5536],\n",
      "        [-1.4320, -1.1665, -1.9518],\n",
      "        [ 1.3035,  1.4920,  0.8639],\n",
      "        [-0.2663,  2.3784, -2.3765]])\n",
      "torch.Size([5, 3])\n",
      "norms :  torch.Size([5])\n",
      "\n",
      "The points are not collinear, we can continue\n"
     ]
    }
   ],
   "source": [
    "# Test of non-collinearity\n",
    "v1 = P2 - P1\n",
    "print(\"v1 = \\n\", v1)  # Print v1 to check the values\n",
    "print(v1.shape)  # (batch_size, 3)\n",
    "v2 = P3 - P1\n",
    "\n",
    "norms = torch.norm(torch.cross(v1,v2, dim=1),dim = 1 )\n",
    "print(\"norms : \",norms.shape)  # (batch_size,)\n",
    "\n",
    "all_dif_zero = torch.all(norms != 0)  # Check if all norms are non-zero\n",
    "\n",
    "if not all_dif_zero:\n",
    "    print('\\nProblem: the points must not be collinear')\n",
    "else:\n",
    "    print('\\nThe points are not collinear, we can continue')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Creation of an orthonormal frame from f1, f2, f3 (the features vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tx =  tensor([[-0.0899, -0.2642,  0.9603],\n",
      "        [-0.2872, -0.0671,  0.9555],\n",
      "        [ 0.2518, -0.0578,  0.9661],\n",
      "        [-0.0925, -0.0345,  0.9951],\n",
      "        [-0.1029,  0.3170,  0.9428]], dtype=torch.float64)\n",
      "torch.Size([5, 3])\n",
      "tz =  tensor([[-0.7166, -0.6525, -0.2466],\n",
      "        [-0.2051,  0.9787,  0.0070],\n",
      "        [-0.5491, -0.8305,  0.0935],\n",
      "        [ 0.7760,  0.6237,  0.0938],\n",
      "        [ 0.9940, -0.0022,  0.1092]], dtype=torch.float64)\n",
      "torch.Size([5, 3])\n",
      "ty =  tensor([[-0.6917,  0.7103,  0.1306],\n",
      "        [ 0.9357,  0.1939,  0.2949],\n",
      "        [-0.7969,  0.5540,  0.2408],\n",
      "        [ 0.6239, -0.7809,  0.0309],\n",
      "        [-0.0367, -0.9484,  0.3149]], dtype=torch.float64)\n",
      "torch.Size([5, 3])\n"
     ]
    }
   ],
   "source": [
    "# Calculation of vectors of the base τ = (C,tx,ty,tz)\n",
    "tx = f1     \n",
    "print(\"tx = \", tx)\n",
    "print(tx.shape)  # (batch_size,3)\n",
    "\n",
    "tz = torch.cross(f1,f2,dim=1)/ torch.norm(torch.cross(f1,f2,dim=1),dim=1, keepdim=True)  # Normalize the cross product to get tz\n",
    "print(\"tz = \", tz)\n",
    "print(tz.shape)  # (batch_size,3)\n",
    "\n",
    "ty = torch.cross(tz,tx,dim=1)\n",
    "print(\"ty = \", ty)\n",
    "print(ty.shape)  # (batch_size,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. (bis) Creation of a transformation matrix T and expression of the f3 vector in this frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tx = \n",
      " tensor([[[-0.0899, -0.2642,  0.9603]],\n",
      "\n",
      "        [[-0.2872, -0.0671,  0.9555]],\n",
      "\n",
      "        [[ 0.2518, -0.0578,  0.9661]],\n",
      "\n",
      "        [[-0.0925, -0.0345,  0.9951]],\n",
      "\n",
      "        [[-0.1029,  0.3170,  0.9428]]], dtype=torch.float64)\n",
      "torch.Size([5, 1, 3])\n",
      "ty = \n",
      " tensor([[[-0.6917,  0.7103,  0.1306]],\n",
      "\n",
      "        [[ 0.9357,  0.1939,  0.2949]],\n",
      "\n",
      "        [[-0.7969,  0.5540,  0.2408]],\n",
      "\n",
      "        [[ 0.6239, -0.7809,  0.0309]],\n",
      "\n",
      "        [[-0.0367, -0.9484,  0.3149]]], dtype=torch.float64)\n",
      "torch.Size([5, 1, 3])\n",
      "tz = \n",
      " tensor([[[-0.7166, -0.6525, -0.2466]],\n",
      "\n",
      "        [[-0.2051,  0.9787,  0.0070]],\n",
      "\n",
      "        [[-0.5491, -0.8305,  0.0935]],\n",
      "\n",
      "        [[ 0.7760,  0.6237,  0.0938]],\n",
      "\n",
      "        [[ 0.9940, -0.0022,  0.1092]]], dtype=torch.float64)\n",
      "torch.Size([5, 1, 3])\n",
      "T = \n",
      " tensor([[[-0.0899, -0.2642,  0.9603],\n",
      "         [-0.6917,  0.7103,  0.1306],\n",
      "         [-0.7166, -0.6525, -0.2466]],\n",
      "\n",
      "        [[-0.2872, -0.0671,  0.9555],\n",
      "         [ 0.9357,  0.1939,  0.2949],\n",
      "         [-0.2051,  0.9787,  0.0070]],\n",
      "\n",
      "        [[ 0.2518, -0.0578,  0.9661],\n",
      "         [-0.7969,  0.5540,  0.2408],\n",
      "         [-0.5491, -0.8305,  0.0935]],\n",
      "\n",
      "        [[-0.0925, -0.0345,  0.9951],\n",
      "         [ 0.6239, -0.7809,  0.0309],\n",
      "         [ 0.7760,  0.6237,  0.0938]],\n",
      "\n",
      "        [[-0.1029,  0.3170,  0.9428],\n",
      "         [-0.0367, -0.9484,  0.3149],\n",
      "         [ 0.9940, -0.0022,  0.1092]]], dtype=torch.float64)\n",
      "torch.Size([5, 3, 3])\n",
      "f3_T = \n",
      " tensor([[[ 0.8937],\n",
      "         [ 0.4359],\n",
      "         [-0.1065]],\n",
      "\n",
      "        [[ 0.9614],\n",
      "         [ 0.2135],\n",
      "         [ 0.1736]],\n",
      "\n",
      "        [[ 0.9643],\n",
      "         [ 0.2457],\n",
      "         [-0.0984]],\n",
      "\n",
      "        [[ 0.9717],\n",
      "         [-0.0821],\n",
      "         [ 0.2217]],\n",
      "\n",
      "        [[ 0.9075],\n",
      "         [ 0.2503],\n",
      "         [ 0.3372]]], dtype=torch.float64)\n",
      "torch.Size([5, 3, 1])\n"
     ]
    }
   ],
   "source": [
    "tx = torch.reshape(tx,(batch_size,1,3))   # (batch_sizee,1,3)\n",
    "print(\"tx = \\n\", tx)\n",
    "print(tx.shape)  # (batch_size,1,3)\n",
    "\n",
    "ty = torch.reshape(ty,(batch_size,1,3))\n",
    "print(\"ty = \\n\", ty)\n",
    "print(ty.shape)  # (batch_size,1,3)\n",
    "\n",
    "tz = torch.reshape(tz,(batch_size,1,3))\n",
    "print(\"tz = \\n\", tz)\n",
    "print(tz.shape)  # (batch_size,1,3)\n",
    "\n",
    "# Computation of the matrix T and the feature vector f3\n",
    "T = torch.cat((tx,ty,tz),dim = 1) # (3*3)\n",
    "print(\"T = \\n\", T)\n",
    "print(T.shape)  # (batch_size,3,3)\n",
    "\n",
    "\n",
    "f3_T = torch.matmul(T,f3.unsqueeze(-1)) # (\n",
    "print(\"f3_T = \\n\", f3_T)\n",
    "print(f3_T.shape)  # (batch_size,3,1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sing of the z-coordinate in f3_T give us the sign of teta, that we will need after "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.1065],\n",
      "        [ 0.1736],\n",
      "        [-0.0984],\n",
      "        [ 0.2217],\n",
      "        [ 0.3372]], dtype=torch.float64)\n",
      "f3_T_positif = \n",
      " tensor([[False],\n",
      "        [ True],\n",
      "        [False],\n",
      "        [ True],\n",
      "        [ True]])\n",
      "torch.Size([5, 1])\n"
     ]
    }
   ],
   "source": [
    "print(f3_T[:,2])\n",
    "f3_T_positif = f3_T[:,2] > 0\n",
    "\n",
    "print(\"f3_T_positif = \\n\", f3_T_positif)\n",
    "print(f3_T_positif.shape)  # (batch_size,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Change of frame is performed on the 3D points side, and the transformation matrix N is defined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nx :  torch.Size([5, 3])\n",
      "nz :  torch.Size([5, 3])\n",
      "ny :  torch.Size([5, 3])\n",
      "nx = \n",
      " tensor([[[-0.6817, -0.7299, -0.0499]],\n",
      "\n",
      "        [[ 0.9569, -0.1990, -0.2116]],\n",
      "\n",
      "        [[-0.5329, -0.4341, -0.7263]],\n",
      "\n",
      "        [[ 0.6031,  0.6903,  0.3997]],\n",
      "\n",
      "        [[-0.0790,  0.7052, -0.7046]]])\n",
      "torch.Size([5, 1, 3])\n",
      "ny = \n",
      " tensor([[[ 0.4599, -0.3746, -0.8051]],\n",
      "\n",
      "        [[-0.2905, -0.6534, -0.6991]],\n",
      "\n",
      "        [[-0.4612, -0.5706,  0.6794]],\n",
      "\n",
      "        [[ 0.7768, -0.6221, -0.0976]],\n",
      "\n",
      "        [[ 0.7658,  0.4954,  0.4100]]])\n",
      "nz = \n",
      " tensor([[[ 5.6896e-01, -5.7179e-01,  5.9105e-01]],\n",
      "\n",
      "        [[ 8.0737e-04,  7.3040e-01, -6.8302e-01]],\n",
      "\n",
      "        [[-7.0942e-01,  6.9708e-01,  1.0390e-01]],\n",
      "\n",
      "        [[ 1.8129e-01,  3.6933e-01, -9.1144e-01]],\n",
      "\n",
      "        [[ 6.3816e-01, -5.0725e-01, -5.7917e-01]]])\n",
      "N = \n",
      " tensor([[[-6.8173e-01, -7.2990e-01, -4.9859e-02],\n",
      "         [ 4.5992e-01, -3.7457e-01, -8.0509e-01],\n",
      "         [ 5.6896e-01, -5.7179e-01,  5.9105e-01]],\n",
      "\n",
      "        [[ 9.5688e-01, -1.9897e-01, -2.1164e-01],\n",
      "         [-2.9048e-01, -6.5340e-01, -6.9906e-01],\n",
      "         [ 8.0737e-04,  7.3040e-01, -6.8302e-01]],\n",
      "\n",
      "        [[-5.3292e-01, -4.3410e-01, -7.2633e-01],\n",
      "         [-4.6121e-01, -5.7064e-01,  6.7945e-01],\n",
      "         [-7.0942e-01,  6.9708e-01,  1.0390e-01]],\n",
      "\n",
      "        [[ 6.0310e-01,  6.9031e-01,  3.9968e-01],\n",
      "         [ 7.7679e-01, -6.2215e-01, -9.7603e-02],\n",
      "         [ 1.8129e-01,  3.6933e-01, -9.1144e-01]],\n",
      "\n",
      "        [[-7.8962e-02,  7.0518e-01, -7.0462e-01],\n",
      "         [ 7.6584e-01,  4.9539e-01,  4.0997e-01],\n",
      "         [ 6.3816e-01, -5.0725e-01, -5.7917e-01]]])\n",
      "torch.Size([5, 3, 3])\n",
      "P3.shape =  torch.Size([5, 3])\n",
      "P3_n = \n",
      " tensor([[[ 2.4614e+00],\n",
      "         [ 7.8930e-01],\n",
      "         [ 5.9605e-08]],\n",
      "\n",
      "        [[ 1.5524e+00],\n",
      "         [ 1.9213e+00],\n",
      "         [ 1.1921e-07]],\n",
      "\n",
      "        [[ 3.9677e-01],\n",
      "         [ 1.7620e+00],\n",
      "         [-1.1176e-07]],\n",
      "\n",
      "        [[-5.8734e-01],\n",
      "         [ 1.4255e+00],\n",
      "         [-5.9605e-08]],\n",
      "\n",
      "        [[ 4.9928e-01],\n",
      "         [ 2.0269e+00],\n",
      "         [-1.1921e-07]]])\n",
      "torch.Size([5, 3, 1])\n"
     ]
    }
   ],
   "source": [
    "# Calculation of vectors of the base η = (P1,nx,ny,nz)\n",
    "nx = (P2 - P1)/torch.norm(P2 - P1,dim=1,keepdim=True)      #(batch_size,3)\n",
    "print(\"nx : \", nx.shape)  # (batch_size,3)\n",
    "\n",
    "nz = torch.cross(nx,P3-P1,dim=1)/torch.norm(torch.cross(nx,P3-P1,dim=1), dim=1, keepdim=True) \n",
    "print(\"nz : \", nz.shape)  # (batch_size,3)\n",
    "\n",
    "ny = torch.cross(nz,nx,dim=1)\n",
    "print(\"ny : \", ny.shape)  # (batch_size,3)\n",
    "\n",
    "\n",
    "# Reshape the vectors to (1,3) for concatenation\n",
    "nx = torch.reshape(nx,(batch_size,1,3))  # (batch_size,1,3)\n",
    "ny = torch.reshape(ny,(batch_size,1,3))\n",
    "nz = torch.reshape(nz,(batch_size,1,3))\n",
    "\n",
    "print(\"nx = \\n\", nx)\n",
    "print(nx.shape)  # (1*3)\n",
    "print(\"ny = \\n\", ny)\n",
    "print(\"nz = \\n\", nz)\n",
    "\n",
    "# Computation of the matrix N and the world point P3\n",
    "N = torch.cat((nx,ny,nz),dim = 1) #  T's equivalent in the world coordinate system\n",
    "print(\"N = \\n\", N)\n",
    "print(N.shape)  # (batch_size,3,3)\n",
    "\n",
    "print(\"P3.shape = \", P3.shape)  # (batch_size,3)\n",
    "\n",
    "P3_n = torch.matmul(N,(P3-P1).unsqueeze(-1)) \n",
    "\n",
    "\n",
    "print(\"P3_n = \\n\", P3_n)\n",
    "print(P3_n.shape)  # (5,3,1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Definition of the variables for the following steps "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "phi1 =  tensor([[-8.3881],\n",
      "        [ 5.5387],\n",
      "        [-9.7957],\n",
      "        [ 4.3832],\n",
      "        [ 2.6916]], dtype=torch.float64)\n",
      "torch.Size([5, 1])\n",
      "phi2 =  tensor([[-4.0914],\n",
      "        [ 1.2302],\n",
      "        [-2.4958],\n",
      "        [-0.3703],\n",
      "        [ 0.7425]], dtype=torch.float64)\n",
      "torch.Size([5, 1])\n",
      "p1 =  tensor([[ 2.4614],\n",
      "        [ 1.5524],\n",
      "        [ 0.3968],\n",
      "        [-0.5873],\n",
      "        [ 0.4993]])\n",
      "torch.Size([5, 1])\n",
      "p2 =  tensor([[0.7893],\n",
      "        [1.9213],\n",
      "        [1.7620],\n",
      "        [1.4255],\n",
      "        [2.0269]])\n",
      "torch.Size([5, 1])\n",
      "d12 =  tensor([[1.4203],\n",
      "        [2.6159],\n",
      "        [2.6871],\n",
      "        [2.1614],\n",
      "        [3.3727]])\n",
      "torch.Size([5, 1])\n",
      "cosBeta =  tensor([[0.9576],\n",
      "        [0.9182],\n",
      "        [0.9583],\n",
      "        [0.9330],\n",
      "        [0.9064]], dtype=torch.float64)\n",
      "torch.Size([5, 1])\n",
      "b =  tensor([[3.3223],\n",
      "        [2.3178],\n",
      "        [3.3517],\n",
      "        [2.5935],\n",
      "        [2.1456]], dtype=torch.float64)\n",
      "torch.Size([5, 1])\n",
      "b =  tensor([[3.3223],\n",
      "        [2.3178],\n",
      "        [3.3517],\n",
      "        [2.5935],\n",
      "        [2.1456]], dtype=torch.float64)\n",
      "torch.Size([5, 1])\n"
     ]
    }
   ],
   "source": [
    "# Computation of phi1 et phi2 with 0=x, 1=y, 2=z\n",
    "phi1 = f3_T[:,0]/f3_T[:,2]\n",
    "phi2 = f3_T[:,1]/f3_T[:,2]\n",
    "print(\"phi1 = \", phi1)\n",
    "print(phi1.shape)  # (batch_size,1)\n",
    "print(\"phi2 = \", phi2)\n",
    "print(phi2.shape)  # (batch_size,1)\n",
    "\n",
    "# Extraction of p1 and p2 from P3_eta\n",
    "p1 = P3_n[:,0] #x\n",
    "p2 = P3_n[:,1] #y\n",
    "print(\"p1 = \", p1)\n",
    "print(p1.shape)  # (batch_size,3)\n",
    "print(\"p2 = \", p2)\n",
    "print(p2.shape)  # (batch_size,3)\n",
    "\n",
    "# Computation of d12\n",
    "d12 = torch.norm(P2-P1,dim=1, keepdim=True) \n",
    "print(\"d12 = \", d12)\n",
    "print(d12.shape)  # (batch_size,1)\n",
    "\n",
    "# Computation of b = cot(beta)\n",
    "cosBeta =( torch.sum(f1*f2,dim=1)/(torch.norm(f1,dim=1)*torch.norm(f2,dim=1)) ).unsqueeze(-1)  # tensor.dot(a,b) <=> tensor.sum(a*b)\n",
    "print(\"cosBeta = \", cosBeta)  \n",
    "print(cosBeta.shape)  # (batch_size,1)\n",
    "\n",
    "b = torch.sqrt(1/(1-cosBeta**2)-1)\n",
    "print(\"b = \", b)\n",
    "print(b.shape)  # (batch_size,1)\n",
    "\n",
    "b = torch.where(cosBeta < 0, -b, b)  # If cosBeta < 0, then b = -b\n",
    "print(\"b = \", b)\n",
    "print(b.shape)  # (batch_size,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Calculation of the coefficients of the polynomial "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a4 =  tensor([[ -34.1934],\n",
      "        [-452.2740],\n",
      "        [-994.6210],\n",
      "        [ -84.0288],\n",
      "        [-148.4714]], dtype=torch.float64)\n",
      "torch.Size([5, 1])\n",
      "a3 =  tensor([[ 34.3855],\n",
      "        [-36.6696],\n",
      "        [ -6.4190],\n",
      "        [ 57.2493],\n",
      "        [ 74.7082]], dtype=torch.float64)\n",
      "a3.shape =  torch.Size([5, 1])\n",
      "a2 =  tensor([[   4.3184],\n",
      "        [ 304.0250],\n",
      "        [-435.8506],\n",
      "        [   6.8745],\n",
      "        [-157.1612]], dtype=torch.float64)\n",
      "torch.Size([5, 1])\n",
      "a1 =  tensor([[-10.6573],\n",
      "        [ 84.2075],\n",
      "        [ 76.1178],\n",
      "        [  1.0279],\n",
      "        [  3.7309]], dtype=torch.float64)\n",
      "torch.Size([5, 1])\n",
      "a0 =  tensor([[5.8565e+00],\n",
      "        [8.3859e+00],\n",
      "        [1.1738e+03],\n",
      "        [4.1781e-03],\n",
      "        [8.3338e+01]], dtype=torch.float64)\n",
      "torch.Size([5, 1])\n"
     ]
    }
   ],
   "source": [
    "a4 = - phi2**2 * p2**4 - phi1**2 * p2**4 - p2**4\n",
    "a3 = 2 * p2**3 * d12 * b + 2 * phi2**2 * p2**3 * d12 * b - 2 * phi1 * phi2 * p2**3 * d12\n",
    "a2 = - phi2**2 * p1**2 * p2**2 - phi2**2 * p2**2 * d12**2 * b**2 - phi2**2 * p2**2 * d12**2 + phi2**2 * p2**4 + phi1**2 * p2 **4 + 2 * p1 * p2**2 * d12 + 2 * phi1 * phi2 * p1 * p2**2 * d12 * b - phi1**2 * p1**2 * p2**2 + 2 * phi2**2 * p1 * p2**2 * d12 - p2**2 * d12**2 * b**2 - 2 * p1**2 * p2**2\n",
    "a1 = 2 * p1**2 * p2 * d12 * b + 2 * phi1 * phi2 * p2**3 * d12 - 2 * phi2**2 * p2**3 * d12 * b - 2 * p1 * p2 * d12**2 * b\n",
    "a0 = - 2 * phi1 * phi2 * p1 * p2**2 * d12 * b + phi2**2 * p2**2 * d12**2 + 2 * p1**3 * d12 - p1**2 * d12**2 + phi2**2 * p1**2 * p2**2 - p1**4 - 2 * phi2**2 * p1 * p2**2 * d12 + phi1**2 * p1**2 * p2**2 + phi2**2 * p2**2 * d12**2 * b**2\n",
    "\n",
    "print(\"a4 = \", a4)\n",
    "print(a4.shape)  # (batch_size,1)\n",
    "print(\"a3 = \", a3)\n",
    "print(\"a3.shape = \", a3.shape)  # (batch_size,1)\n",
    "print(\"a2 = \", a2)\n",
    "print(a2.shape)  # (batch_size,1)\n",
    "print(\"a1 = \", a1)\n",
    "print(a1.shape)  # (batch_size,1)\n",
    "print(\"a0 = \", a0)\n",
    "print(a0.shape)  # (batch_size,1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. Recovery of the polynomial roots cos (teta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "vmap: It looks like you're attempting to use a Tensor in some data-dependent control flow. We don't support that yet, please shout over at https://github.com/pytorch/functorch/issues/257 .",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[78]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m vmap\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# Computation of the roots\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m roots = \u001b[43mvmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpolynomial_root_calculation_4th_degree_ferrari\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43ma0\u001b[49m\u001b[43m,\u001b[49m\u001b[43ma1\u001b[49m\u001b[43m,\u001b[49m\u001b[43ma2\u001b[49m\u001b[43m,\u001b[49m\u001b[43ma3\u001b[49m\u001b[43m,\u001b[49m\u001b[43ma4\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdim\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# (batch_size,4)\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mroots = \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m, roots)  \u001b[38;5;66;03m# list of tensor (for complex numbers)\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\_functorch\\apis.py:202\u001b[39m, in \u001b[36mvmap.<locals>.wrapped\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    201\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapped\u001b[39m(*args, **kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m202\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mvmap_impl\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    203\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43min_dims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout_dims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandomness\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunk_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    204\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\_functorch\\vmap.py:334\u001b[39m, in \u001b[36mvmap_impl\u001b[39m\u001b[34m(func, in_dims, out_dims, randomness, chunk_size, *args, **kwargs)\u001b[39m\n\u001b[32m    323\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _chunked_vmap(\n\u001b[32m    324\u001b[39m         func,\n\u001b[32m    325\u001b[39m         flat_in_dims,\n\u001b[32m   (...)\u001b[39m\u001b[32m    330\u001b[39m         **kwargs,\n\u001b[32m    331\u001b[39m     )\n\u001b[32m    333\u001b[39m \u001b[38;5;66;03m# If chunk_size is not specified.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m334\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_flat_vmap\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    335\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    336\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    337\u001b[39m \u001b[43m    \u001b[49m\u001b[43mflat_in_dims\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    338\u001b[39m \u001b[43m    \u001b[49m\u001b[43mflat_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    339\u001b[39m \u001b[43m    \u001b[49m\u001b[43margs_spec\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    340\u001b[39m \u001b[43m    \u001b[49m\u001b[43mout_dims\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    341\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrandomness\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    342\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    343\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\_functorch\\vmap.py:484\u001b[39m, in \u001b[36m_flat_vmap\u001b[39m\u001b[34m(func, batch_size, flat_in_dims, flat_args, args_spec, out_dims, randomness, **kwargs)\u001b[39m\n\u001b[32m    480\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m vmap_increment_nesting(batch_size, randomness) \u001b[38;5;28;01mas\u001b[39;00m vmap_level:\n\u001b[32m    481\u001b[39m     batched_inputs = _create_batched_inputs(\n\u001b[32m    482\u001b[39m         flat_in_dims, flat_args, vmap_level, args_spec\n\u001b[32m    483\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m484\u001b[39m     batched_outputs = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43mbatched_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    485\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _unwrap_batched(batched_outputs, out_dims, vmap_level, batch_size, func)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[73]\u001b[39m\u001b[32m, line 57\u001b[39m, in \u001b[36mpolynomial_root_calculation_4th_degree_ferrari\u001b[39m\u001b[34m(a)\u001b[39m\n\u001b[32m     53\u001b[39m b2 = b - \u001b[32m6\u001b[39m * S**\u001b[32m2\u001b[39m\n\u001b[32m     56\u001b[39m \u001b[38;5;66;03m# Solve the cubic equation m^3 + b2*m^2 + (b2^2/4  - b0)*m - b1^2/8 = 0\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m57\u001b[39m x_cube = \u001b[43mpolynomial_root_calculation_3rd_degree\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mb2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb2\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m/\u001b[49m\u001b[32;43m4\u001b[39;49m\u001b[43m-\u001b[49m\u001b[43mb0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m(\u001b[49m\u001b[43m-\u001b[49m\u001b[43mb1\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m/\u001b[49m\u001b[32;43m8\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     60\u001b[39m \u001b[38;5;66;03m# Find a real and positive solution\u001b[39;00m\n\u001b[32m     61\u001b[39m condition = (torch.isclose(x_cube[:,\u001b[32m1\u001b[39m],torch.tensor(\u001b[32m0.0\u001b[39m,dtype=torch.float64),atol=\u001b[32m1e-7\u001b[39m)) & (x_cube[:,\u001b[32m0\u001b[39m] > \u001b[32m0\u001b[39m) \n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[73]\u001b[39m\u001b[32m, line 22\u001b[39m, in \u001b[36mpolynomial_root_calculation_3rd_degree\u001b[39m\u001b[34m(a, b, c, d)\u001b[39m\n\u001b[32m     18\u001b[39m k = torch.tensor([\u001b[32m0\u001b[39m,\u001b[32m1\u001b[39m,\u001b[32m2\u001b[39m])\n\u001b[32m     20\u001b[39m delta_sur_27 = -delta / \u001b[32m27\u001b[39m          \u001b[38;5;66;03m# reéls\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m22\u001b[39m sqrt_term = \u001b[43msqrt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdelta_sur_27\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Use the sqrt function defined above\u001b[39;00m\n\u001b[32m     23\u001b[39m u_k = product_of_2_complex_numbers(complex_number_power_k(j_,k), sqrt_3(torch.tensor([\u001b[32m0.5\u001b[39m*(-q+sqrt_term[\u001b[32m0\u001b[39m]),sqrt_term[\u001b[32m1\u001b[39m]])) )\u001b[38;5;66;03m# because q real \u001b[39;00m\n\u001b[32m     24\u001b[39m v_k = product_of_2_complex_numbers(complex_number_power_k(j_,-k), sqrt_3(torch.tensor([\u001b[32m0.5\u001b[39m*(-q-sqrt_term[\u001b[32m0\u001b[39m]),-\u001b[32m0.5\u001b[39m*sqrt_term[\u001b[32m1\u001b[39m]])))\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\pmamalet\\Documents\\Stage\\poseidon\\pnp_torch_implementation\\complex_utils.py:77\u001b[39m, in \u001b[36msqrt\u001b[39m\u001b[34m(a)\u001b[39m\n\u001b[32m     75\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34msqrt\u001b[39m(a):\n\u001b[32m     76\u001b[39m     \u001b[38;5;66;03m# a real \u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m77\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m a < \u001b[32m0\u001b[39m:\n\u001b[32m     78\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m torch.tensor([\u001b[32m0.0\u001b[39m, torch.sqrt(torch.tensor(-a))]) \n\u001b[32m     79\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m : \n",
      "\u001b[31mRuntimeError\u001b[39m: vmap: It looks like you're attempting to use a Tensor in some data-dependent control flow. We don't support that yet, please shout over at https://github.com/pytorch/functorch/issues/257 ."
     ]
    }
   ],
   "source": [
    "from torch import vmap\n",
    "\n",
    "# Computation of the roots\n",
    "roots = vmap(polynomial_root_calculation_4th_degree_ferrari)(torch.cat([a0,a1,a2,a3,a4],dim=1)) # (batch_size,4)\n",
    "\n",
    "print(\"roots = \\n\", roots)  # list of tensor (for complex numbers)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. For each solution : computation of the camera position and rotation matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each solution of the polynomial\n",
    "for i in range(4):\n",
    "  #if np.isclose(np.imag(roots[i]),0) : # if real solution \n",
    "\n",
    "    # Computation of trigonometrics forms\n",
    "    cos_teta = torch.tensor(roots[i][0])# real part of the root \n",
    "    sin_teta = torch.sqrt(1-cos_teta**2)\n",
    "\n",
    "    cot_alpha = ((phi1/phi2)*p1 + cos_teta*p2 -d12*b )/ ((phi1/phi2)*cos_teta* p2 - p1 + d12)\n",
    "\n",
    "    sin_alpha = torch.sqrt(1/(cot_alpha**2+1))\n",
    "    cos_alpha= torch.sqrt(1-sin_alpha**2)\n",
    "\n",
    "    if cot_alpha < 0 :\n",
    "      cos_alpha = -cos_alpha\n",
    "\n",
    "    # Computation of the intermediate rotation's matrixs\n",
    "    C_estimate = torch.tensor([d12*cos_alpha*(sin_alpha*b + cos_alpha), d12*sin_alpha*cos_teta*(sin_alpha*b+cos_alpha), d12*sin_alpha*sin_teta*(sin_alpha*b+cos_alpha)]) # (3,)\n",
    "    print(\"C_estimate = \\n\", C_estimate)\n",
    "    print(C_estimate.shape)  # (3,)\n",
    "    Q = torch.tensor([[-cos_alpha, -sin_alpha*cos_teta, -sin_alpha*sin_teta], [sin_alpha, -cos_alpha*cos_teta, -cos_alpha*sin_teta], [0, -sin_teta, cos_teta]])    # (3*3)\n",
    "    print(\"Q = \\n\", Q)\n",
    "    print(Q.shape)  # (3,3)\n",
    "    # Computation of the absolute camera center\n",
    "  \n",
    "    C_estimate = P1 + torch.tensordot(torch.transpose(N, 0,1), C_estimate, dims=1) # (3,)\n",
    "    print(\"C_estimate = \\n\", C_estimate) \n",
    "    print(C_estimate.shape)  # (3,)\n",
    "    C_estimate = torch.reshape(C_estimate, (3,1))  # Reshape to (3,1) for consistency\n",
    "    print(\"C_estimate = \\n\", C_estimate)  # (3,1)\n",
    "    print(\"C_estimate.shape = \", C_estimate.shape)  # (3,1)\n",
    "\n",
    "    # Computation of the orientation matrix\n",
    "    R_estimate = torch.tensordot(torch.tensordot(torch.transpose(N,0,1),torch.transpose(Q, 0,1), dims=1),T,dims=1)   # (3*3)\n",
    "    print(\"R_estimate = \\n\", R_estimate)\n",
    "    print(R_estimate.shape)  # (3,3)\n",
    "    \n",
    "    # Adding C and R to the solutions\n",
    "    solutions[i,:,:1]= C_estimate\n",
    "    solutions[i,:,1:] = R_estimate\n",
    "\n",
    "print(\"solutions = \\n\", solutions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"solutions = \\n\", solutions)\n",
    "print(solutions.shape)  # (4,3,4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11. Reprojection of points in 2D from the newly estimated matrices to verify the estimation error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def projection3D2D(point3D,C,R,A) :\n",
    "  # 3D point = [ Xw, Yw, Zw ]'   (1*3)\n",
    "  # T : camera translation matrix : (3*1)\n",
    "  # R : camera rotation matrix : (3*3)\n",
    "  # A : intraseca matrix of the camera : (3*3)\n",
    "  # Output : return the coordonates of the point in 2D \n",
    "\n",
    "  PI = torch.cat((torch.eye(3, dtype=torch.float64),torch.zeros((3,1), dtype=torch.float64)),dim=1)  # (3*4)\n",
    "\n",
    "  Rt = torch.cat((R,C),dim=1)               # (3*4)\n",
    "  Rt = torch.cat((Rt,torch.tensor([[0,0,0,1]], dtype=torch.float64)),dim=0)   # (4*4)\n",
    "\n",
    "  point3D_bis = torch.cat((torch.reshape(point3D,(3,1)),torch.tensor([[1]],dtype=torch.float64)),dim=0)   #(4*1)\n",
    "  \n",
    "  point2D = torch.tensordot(torch.tensordot(torch.tensordot(A,PI,dims=1),Rt,dims=1),point3D_bis,dims=1)  # 2D point = [u, v, w] (3*1)\n",
    "  point2D = point2D / point2D[2]        # 2D point = [u, v, 1] (3*1)\n",
    "  return point2D[:2]\n",
    "\n",
    "\n",
    "C_transpose = torch.transpose(C, 0, 1)  # (3*1) -> (1*3)\n",
    "\n",
    "p1 = projection3D2D(P1,C_transpose,R,A)\n",
    "print(\"p1 = \", p1)\n",
    "print(p1.shape)  # (2,1)\n",
    "p2 = projection3D2D(points3D[1],C_transpose,R,A)\n",
    "print(\"p2 = \", p2)\n",
    "p3 = projection3D2D(points3D[2],C_transpose,R,A)\n",
    "print(\"p3 = \", p3)\n",
    "p4 = projection3D2D(P4,C_transpose,R,A)\n",
    "print(\"p4 = \", p4)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12. Calculation of errors = distance between the 2D points estimated from the found rotation and position matrices and the 2D points from the initial matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance(pt, pt_estimation):\n",
    "    erreur = torch.tensor(0, dtype=torch.float64)  # Initialize error as a tensor\n",
    "    for i in range(len(pt)): \n",
    "      erreur = erreur + torch.tensor((pt[i] - pt_estimation[i])**2, dtype=torch.float64)  # Ensure each term is a tensor\n",
    "      #erreur += (pt[i] - pt_estimation[i])**2\n",
    "    return torch.sqrt(erreur)\n",
    "\n",
    "\n",
    "\n",
    "def affichage_erreur(solutions,points2D,points3D,A) : \n",
    "   # Compute the error of estimation for each points after the P3P algorithm \n",
    "\n",
    "   # solutions : solution matrix returned by P3P (4*3*4)\n",
    "   # points 3D : 4 pts 3D used for P3P \n",
    "   # points 2D : 4 pts 2D used for P3P (image of the 3D points)\n",
    "   \n",
    "   P1 = points3D[0]\n",
    "   P2 = points3D[1]\n",
    "   P3 = points3D[2]\n",
    "   P4 = points3D[3]\n",
    "\n",
    "   erreurs = []\n",
    "   nb_sol = 0\n",
    "\n",
    "   for i in range(len(solutions)) : \n",
    "      R = solutions[i,:,1:] \n",
    "      C = solutions[i,:,:1]\n",
    "\n",
    "      if not torch.all(R==torch.zeros((3,3))) : \n",
    "        nb_sol += 1 \n",
    "        print(\"------------ Solution n° : \",nb_sol,\"----------------\")\n",
    "        print(\"R = \\n\",R,)\n",
    "        print(\"T = \\n\",C,)\n",
    "\n",
    "        p1_P3P = torch.reshape(projection3D2D(P1,C,R,A),(1,2))\n",
    "        p2_P3P = torch.reshape(projection3D2D(P2,C,R,A),(1,2))\n",
    "        p3_P3P = torch.reshape(projection3D2D(P3,C,R,A),(1,2))\n",
    "        p4_P3P = torch.reshape(projection3D2D(P4,C,R,A),(1,2))\n",
    "        pt_2D_P3P = torch.cat((p1_P3P,p2_P3P,p3_P3P,p4_P3P),dim=0)    # (4,2)\n",
    "\n",
    "        erreurs.append([0])\n",
    "        for j in range(len(points2D)):\n",
    "            erreur_pt = distance(points2D[j],pt_2D_P3P[j])\n",
    "            erreurs[i]+=erreur_pt\n",
    "        \n",
    "   indice_min = 0\n",
    "   min = erreurs[0]\n",
    "   for i in range(1,len(erreurs)) :\n",
    "    if erreurs[i]<min :\n",
    "      min = erreurs[i]\n",
    "      indice_min = i\n",
    "\n",
    "   R_opti = solutions[indice_min,:,1:] \n",
    "   C_opti = solutions[indice_min,:,:1]\n",
    "   print(\"\\n------------ Best solution : ----------------\")\n",
    "   print(\"Solution n° :\",indice_min+1,\"\\n\")\n",
    "   print(\"R estimé = \\n\", R_opti,\"\\n\")\n",
    "   print(\"T estimé = \\n\", C_opti, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "affichage_erreur(solutions, [p1, p2, p3, p4], [P1,P2,P3, P4], A)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
