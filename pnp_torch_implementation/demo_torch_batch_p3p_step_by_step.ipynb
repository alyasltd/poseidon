{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import torch\n",
    "\n",
    "batch_size = 5\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At first we have : \n",
    "- camera's parameters -> A (focal, center) \n",
    "- rotation matrix  -> R \n",
    "- position matrix -> C \n",
    "- 3D points position ->  P1 P2 P3 (and P4 to determinate the best solution after P3P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A_batch = \n",
      " tensor([[[800.,   0., 320.],\n",
      "         [  0., 800., 240.],\n",
      "         [  0.,   0.,   1.]],\n",
      "\n",
      "        [[800.,   0., 320.],\n",
      "         [  0., 800., 240.],\n",
      "         [  0.,   0.,   1.]],\n",
      "\n",
      "        [[800.,   0., 320.],\n",
      "         [  0., 800., 240.],\n",
      "         [  0.,   0.,   1.]],\n",
      "\n",
      "        [[800.,   0., 320.],\n",
      "         [  0., 800., 240.],\n",
      "         [  0.,   0.,   1.]],\n",
      "\n",
      "        [[800.,   0., 320.],\n",
      "         [  0., 800., 240.],\n",
      "         [  0.,   0.,   1.]]], dtype=torch.float64)\n",
      "torch.Size([5, 3, 3])\n",
      "R_batch = \n",
      " tensor([[[ 1.,  0.,  0.],\n",
      "         [ 0., -1.,  0.],\n",
      "         [ 0.,  0., -1.]],\n",
      "\n",
      "        [[ 1.,  0.,  0.],\n",
      "         [ 0., -1.,  0.],\n",
      "         [ 0.,  0., -1.]],\n",
      "\n",
      "        [[ 1.,  0.,  0.],\n",
      "         [ 0., -1.,  0.],\n",
      "         [ 0.,  0., -1.]],\n",
      "\n",
      "        [[ 1.,  0.,  0.],\n",
      "         [ 0., -1.,  0.],\n",
      "         [ 0.,  0., -1.]],\n",
      "\n",
      "        [[ 1.,  0.,  0.],\n",
      "         [ 0., -1.,  0.],\n",
      "         [ 0.,  0., -1.]]], dtype=torch.float64)\n",
      "torch.Size([5, 3, 3])\n",
      "C_batch = \n",
      " tensor([[0., 0., 6.],\n",
      "        [0., 0., 6.],\n",
      "        [0., 0., 6.],\n",
      "        [0., 0., 6.],\n",
      "        [0., 0., 6.]], dtype=torch.float64)\n",
      "torch.Size([5, 3])\n",
      "batch_size =  5\n"
     ]
    }
   ],
   "source": [
    "# This script defines the camera parameters, rotation matrix, and translation matrix.\n",
    "def camera() : \n",
    "  # Definition of the camera parameters\n",
    "  # focal length\n",
    "  fx = 800\n",
    "  fy = 800\n",
    "  # center\n",
    "  cx = 320 \n",
    "  cy = 240\n",
    "\n",
    "  A = torch.tensor([[fx, 0, cx], [0, fy, cy], [0, 0, 1]], dtype=torch.float64) # intraseca matrix of the camera (3*3)\n",
    "  \n",
    "  A_batch = A.repeat(batch_size,1,1)\n",
    "  print(\"A_batch = \\n\", A_batch)\n",
    "  print(A_batch.shape)  # (batch_size, 3, 3)\n",
    "  return A_batch\n",
    "\n",
    "A = camera() \n",
    "\n",
    "\n",
    "\n",
    "def rotation_matrix() : \n",
    "  # Definition of the rotation matrix of the camera \n",
    "  R = torch.tensor([[1, 0, 0],[0, -1, 0], [0, 0, -1]], dtype=torch.float64)  # (3*3)\n",
    "  \n",
    "  R_batch = R.repeat(batch_size,1,1)  # Repeat the rotation matrix for each batch\n",
    "  print(\"R_batch = \\n\", R_batch)  \n",
    "  print(R_batch.shape)  # (batch_size, 3, 3)\n",
    "  return R_batch\n",
    "\n",
    "def camera_position() : \n",
    "  # Definition of the translation matrix of the camera (the position)\n",
    "  C = torch.tensor([[0,0,6]], dtype=torch.float64)    # T = [tx,ty,tz]  (1*3)\n",
    "  \n",
    "\n",
    "  C_batch = C.repeat(batch_size, 1)  # Repeat the translation vector for each batch\n",
    "  print(\"C_batch = \\n\", C_batch)  \n",
    "  print(C_batch.shape)  # (batch_size, 3)\n",
    "  return C_batch\n",
    "\n",
    "R = rotation_matrix()\n",
    "C = camera_position()\n",
    "print(\"batch_size = \", batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P1 = \n",
      " tensor([[-1.9540,  0.2069, -0.8956],\n",
      "        [-0.7383, -0.4089,  1.4930],\n",
      "        [-0.7537, -1.4189,  0.3761],\n",
      "        [ 1.5705,  1.9770, -0.4704],\n",
      "        [ 0.9455,  0.2458, -1.3549]], dtype=torch.float64)\n",
      "P2 = \n",
      " tensor([[ 1.2113, -1.7463,  1.3000],\n",
      "        [ 1.3310,  0.9893,  0.5098],\n",
      "        [ 1.8508, -0.0950, -1.2739],\n",
      "        [ 0.3550, -1.2609, -1.2266],\n",
      "        [-0.6543,  1.2507, -0.4034]], dtype=torch.float64)\n",
      "P3 = \n",
      " tensor([[ 1.1157, -0.6680,  0.6822],\n",
      "        [-1.6701, -0.2050,  1.6707],\n",
      "        [ 1.0510,  1.8721,  1.4427],\n",
      "        [ 1.0063,  0.4483, -0.0503],\n",
      "        [ 1.7563,  0.5605,  0.5006]], dtype=torch.float64)\n",
      "P4 = \n",
      " tensor([[ 0.9176,  1.4039,  0.0677],\n",
      "        [ 0.3903,  0.9129, -0.4444],\n",
      "        [-0.8640,  0.7269,  0.3751],\n",
      "        [ 1.0400,  1.9423, -1.9324],\n",
      "        [ 1.3146, -1.4322, -0.2448]], dtype=torch.float64)\n",
      "torch.Size([5, 3])\n"
     ]
    }
   ],
   "source": [
    "#torch.manual_seed(1234)  \n",
    "\n",
    "# Definition of 3D points in the world coordinate system\n",
    "def point3Daleatoire(x) :\n",
    "  # Generation of one random points in 3D space \n",
    "  return torch.empty((1, 3), dtype=torch.float64).uniform_(-x, x)\n",
    "\n",
    "\n",
    "def pts_3D_4pts():\n",
    "  # Generate randomly 4 3D points\n",
    "  # Output : tensor which concatenate the 4 points = [ P1, P2, P3, P4 ] \n",
    "\n",
    "  P1 = point3Daleatoire(2)     # (1*3) -> pour P3P\n",
    "  P2 = point3Daleatoire(2)\n",
    "  P3 = point3Daleatoire(2)\n",
    "  P4 = point3Daleatoire(2)\n",
    "  \n",
    "  points3D = torch.cat((P1,P2,P3,P4),dim=0);     # (LIGNES 4* COLONNES 3) - xyz\n",
    "    \n",
    "  return points3D\n",
    "\n",
    "def pts_3D_4pts_batch():\n",
    "  # Generate randomly 4 3D points for each batch\n",
    "  # Output : array which concatenate the 4 points = [ P1, P2, P3, P4 ] for each batch\n",
    "\n",
    "  # Generate a batch of random points in 3D space\n",
    "  # Each point is generated independently for each batch\n",
    "\n",
    "  points3D_batch = torch.stack([pts_3D_4pts() for i in range(batch_size)])  # (batch_size, 4, 3)\n",
    "  \n",
    "  return points3D_batch\n",
    "\n",
    "points3D_batch = pts_3D_4pts_batch()  # Generate the batch of 3D points\n",
    "'''\n",
    "P1 = torch.tensor([0.7161, 0.5431, 1.7807], dtype=torch.float64)    # (3,)\n",
    "P2 = torch.tensor([-1.1643, 0.8371, -1.0551], dtype=torch.float64)\n",
    "P3 = torch.tensor([-1.5224, 0.4292, -0.1994], dtype=torch.float64)\n",
    "P4 = torch.tensor([-1.5224, 0.4292, -0.1994], dtype=torch.float64) \n",
    "'''\n",
    "P1 = points3D_batch[:, 0, :]  # Extract P1 for each batch\n",
    "P2 = points3D_batch[:, 1, :]  # Extract P2 for each batch\n",
    "P3 = points3D_batch[:, 2, :]  # Extract P3 for each batch\n",
    "P4 = points3D_batch[:, 3, :]  # Extract P4 for each batch\n",
    "\n",
    "print(\"P1 = \\n\", P1)\n",
    "print(\"P2 = \\n\", P2)\n",
    "print(\"P3 = \\n\", P3)\n",
    "print(\"P4 = \\n\", P4)\n",
    "print(P1.shape)  # (batch_size, 3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create the 3 direction features vectors f1, f2, f3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "points3D = \n",
      " [tensor([[-1.9540,  0.2069, -0.8956],\n",
      "        [-0.7383, -0.4089,  1.4930],\n",
      "        [-0.7537, -1.4189,  0.3761],\n",
      "        [ 1.5705,  1.9770, -0.4704],\n",
      "        [ 0.9455,  0.2458, -1.3549]], dtype=torch.float64), tensor([[ 1.2113, -1.7463,  1.3000],\n",
      "        [ 1.3310,  0.9893,  0.5098],\n",
      "        [ 1.8508, -0.0950, -1.2739],\n",
      "        [ 0.3550, -1.2609, -1.2266],\n",
      "        [-0.6543,  1.2507, -0.4034]], dtype=torch.float64), tensor([[ 1.1157, -0.6680,  0.6822],\n",
      "        [-1.6701, -0.2050,  1.6707],\n",
      "        [ 1.0510,  1.8721,  1.4427],\n",
      "        [ 1.0063,  0.4483, -0.0503],\n",
      "        [ 1.7563,  0.5605,  0.5006]], dtype=torch.float64)]\n",
      "features vectors = \n",
      " tensor([[[-0.2725, -0.0289,  0.9617],\n",
      "         [ 0.2348,  0.3385,  0.9112],\n",
      "         [ 0.2038,  0.1220,  0.9714]],\n",
      "\n",
      "        [[-0.1610,  0.0892,  0.9829],\n",
      "         [ 0.2321, -0.1725,  0.9573],\n",
      "         [-0.3596,  0.0441,  0.9321]],\n",
      "\n",
      "        [[-0.1289,  0.2426,  0.9615],\n",
      "         [ 0.2466,  0.0127,  0.9690],\n",
      "         [ 0.2086, -0.3716,  0.9046]],\n",
      "\n",
      "        [[ 0.2261, -0.2846,  0.9316],\n",
      "         [ 0.0483,  0.1717,  0.9840],\n",
      "         [ 0.1636, -0.0729,  0.9838]],\n",
      "\n",
      "        [[ 0.1274, -0.0331,  0.9913],\n",
      "         [-0.0998, -0.1907,  0.9766],\n",
      "         [ 0.3028, -0.0966,  0.9481]]], dtype=torch.float64)\n",
      "torch.Size([5, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "def features_vectors(points3D,C, R,batch_size) :\n",
    "    '''\n",
    "    This function computes the features vectors for P3P algorithm.\n",
    "    args:\n",
    "    points3D : array with the 4 3D points = [ P1, P2, P3, P4 ] (4*3) \n",
    "    but we only use the first three points for P3P\n",
    "    C: camera position matrix : (3*1)\n",
    "    returns:\n",
    "    featuresVect : array with the features vectors (9*1)\n",
    "    '''\n",
    "    P1 = torch.reshape(points3D[0], (batch_size,3,1))  # (batch_size, 3, 1)\n",
    "    P2 = torch.reshape(points3D[1], (batch_size,3,1))\n",
    "    P3 = torch.reshape(points3D[2], (batch_size,3,1))\n",
    "\n",
    "    C = torch.reshape(C, (batch_size,3,1))   # (batch_size, 3, 1)\n",
    "    \n",
    "    v1 = torch.matmul(R,(P1 - C))  # (batch_size, 3, 1)\n",
    "    v2 = torch.matmul(R,(P2 - C))  # (batch_size, 3, 1)\n",
    "    v3 = torch.matmul(R,(P3 - C))  # (batch_size, 3, 1)\n",
    "\n",
    "    f1 = v1 / torch.norm(v1,dim=1, keepdim=True)  # (batch_size, 3, 1)\n",
    "    f2 = v2 / torch.norm(v2,dim=1, keepdim=True)  # (batch_size, 3, 1)\n",
    "    f3 = v3 / torch.norm(v3,dim=1, keepdim=True)  # (batch_size, 3, 1)\n",
    "\n",
    "\n",
    "    f1 = torch.reshape(f1, (batch_size,1,3))  # (batch_size,1,3)\n",
    "    f2 = torch.reshape(f2, (batch_size,1,3))\n",
    "    f3 = torch.reshape(f3, (batch_size,1,3))\n",
    "\n",
    "    featuresVect = torch.cat((f1,f2,f3),dim=1) # (batch_size, 3, 3)\n",
    "    print(\"features vectors = \\n\",featuresVect)\n",
    "    print(featuresVect.shape)  \n",
    "\n",
    "    return featuresVect # Return the features vectors need in P3P\n",
    "\n",
    "\n",
    "points3D = [P1, P2, P3]  # We define the points3D with the first three points\n",
    "print(\"points3D = \\n\", points3D)  # Print the points3D to check the values  / List len = 3 \n",
    "\n",
    "featuresVect = features_vectors(points3D, C, R,batch_size)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly we need the functions to resolve the polynomial roots. - for test go to test resolution polynome "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [],
   "source": [
    "from complex_batch_utils import *\n",
    "import complex_utils as cpu\n",
    "from torch import vmap\n",
    "\n",
    "def polynomial_root_calculation_3rd_degree(a, b, c, d):\n",
    "    # This function calculates the roots of a cubic polynomial of the form:\n",
    "    # a*x^3 + b*x^2 + c*x + d = 0\n",
    "        # a (batch_size, 1)\n",
    "        # b (batch_size, 1)\n",
    "        # c (batch_size, 1)\n",
    "        # d (batch_size, 1)\n",
    "\n",
    "    # output: roots of the polynomial in the form of a tensor of shape (batch_size,3, 2)\n",
    "    # where each root is represented as a complex number (real, imaginary)\n",
    "    # each row is the i_th root of the polynomial\n",
    "    \n",
    "    batch_size = a.shape[0]  # Get the batch size from the shape of a\n",
    "    \n",
    "\n",
    "    # Discriminant terms\n",
    "    p = (3 * a * c - b**2) / (3 * a**2)     # (batch_size, 1) because element-wise opeations\n",
    "    q = (2 * b**3 - 9 * a * b * c + 27 * a**2 * d) / (27 * a**3)    # (batch_size, 1)\n",
    "    delta = -4 * p**3 - 27 * q**2   # (batch_size, 1)\n",
    "\n",
    "    roots = torch.empty((batch_size,3, 2))  # Initialize roots tensor to store the roots\n",
    "\n",
    "    j_ = torch.tensor([-0.5, torch.sqrt(torch.tensor(3))/2])  # cube root of unity\n",
    "    \n",
    "    for k in range (3):\n",
    "        delta_sur_27 = -delta / 27   #(batch_size, 1) \n",
    "\n",
    "        sqrt_term = sqrt_batch(delta_sur_27)  \n",
    "\n",
    "        # faire une seule fois les calculs de j^k et j^-k\n",
    "        j_exp_k = cpu.complex_number_power_k(j_, k)  # Compute j^k for each batch\n",
    "        j_exp_moins_k = cpu.complex_number_power_k(j_, -k)  # Compute j^-k for each batch\n",
    "\n",
    "        j_exp_k_batch = j_exp_k.repeat(batch_size, 1)\n",
    "        j_exp_moins_k_batch = j_exp_moins_k.repeat(batch_size, 1)\n",
    "\n",
    "        u_k = product_of_2_complex_numbers_batch(j_exp_k_batch, sqrt_3_batch(torch.stack([0.5*(-q.squeeze()+sqrt_term[:,0]),sqrt_term[:,1]],dim=-1)) )\n",
    "         # (batch_size, 2) \n",
    "        v_k = product_of_2_complex_numbers_batch(j_exp_moins_k_batch, sqrt_3_batch(torch.stack([0.5*(-q.squeeze()-sqrt_term[:,0]),-0.5*sqrt_term[:,1]],dim=-1)))\n",
    "          # (batch_size, 2) \n",
    "\n",
    "        root = addition_batch(addition_batch(u_k, v_k), torch.stack([-b[:,0]/(3*a[:,0]),0.0*b[:,0]],dim=-1) ) \n",
    "         # (batch_size, 2)\n",
    "\n",
    "        roots[:,k,:] = root  # Store the root in the roots tensor\n",
    "\n",
    "    return roots\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def polynomial_root_calculation_4th_degree_ferrari(a0, a1, a2, a3, a4): # Ferrari's Method\n",
    "       \n",
    "    # Solving a polynomial of 4th degree\n",
    "    # a0, a1, a2, a3, a4 (batch_size,1)\n",
    "\n",
    "    # Output : roots of the polynomial a4*x^4 + a3*x^3 + a2*x^2 + a1*x + a0   (4,batch_size 2) !! ATTENTION !!! \n",
    "\n",
    "    batch_size = a0.shape[0]  # Get the batch size from the shape of a0\n",
    "\n",
    "    # Reduce the quartic equation to the form : x^4 + a*x^3 + b*x^2 + c*x + d = 0\n",
    "    a = a3/a4           # (batch_size, 1)\n",
    "    b = a2/a4\n",
    "    c = a1/a4\n",
    "    d = a0/a4\n",
    "\n",
    "    # Computation of the coefficients of the Ferrari's Method\n",
    "    S = a/4     # (batch_size, 1)\n",
    "    b0 = d - c*S + b* S**2 - 3* S**4    # (batch_size, 1)\n",
    "    b1 = c - 2*b*S + 8*S**3 # (batch_size, 1)\n",
    "    b2 = b - 6 * S**2  # (batch_size, 1)\n",
    "\n",
    "\n",
    "    # Solve the cubic equation m^3 + b2*m^2 + (b2^2/4  - b0)*m - b1^2/8 = 0\n",
    "    x_cube = polynomial_root_calculation_3rd_degree(torch.tensor(1).repeat(b2.shape),b2,(b2**2)/4-b0,(-b1**2)/8)\n",
    "  \n",
    "    \n",
    "    x_cube_real = x_cube[:,:,0] #  (batch_size, 3)\n",
    "    x_cube_imag = x_cube[:,:,1]  #    (batch_size, 3)\n",
    "\n",
    "    is_real = torch.isclose(x_cube_imag,torch.tensor(0.0))\n",
    "    is_positive = x_cube[:,:,0] > 0\n",
    "    condition = is_real & is_positive  # Condition to check if the root is real and positive   (batch_size, 3)\n",
    "   \n",
    "    \n",
    "    real_filtered = x_cube_real.clone()\n",
    "    real_filtered[~condition] = float('inf')  # if root real and positive, keep it, else set to infinity   (batch_size, 3)\n",
    "\n",
    "\n",
    "    alpha_0_real, _ = real_filtered.min(dim=1) # Get the minimum real part of the roots (if doesn't exist, returns inf)\n",
    "\n",
    "    alpha_0 = torch.stack([alpha_0_real, torch.zeros(batch_size)], dim=-1)  # (batch_size,2)\n",
    "    \n",
    "\n",
    "    # do the calculation for alpha_0_nul and not alpha_0_nul and then affects the good value \n",
    "\n",
    "    # if alpha_0_nul == False\n",
    "    alpha0_div_2 = 0.5*alpha_0              # beacause alpha_0 is real  # (batch_size, 2)    \n",
    "    sqrt_alpha = sqrt_batch(alpha0_div_2[:,0].unsqueeze(-1))    # input : (batch_size, 1) // output : (batch_size, 2)\n",
    "    term = addition_complex_real_batch(- alpha0_div_2 ,-b2 / 2)      # (batch_size, 2)\n",
    "    denom = 2 * torch.sqrt(2 * alpha_0)      # beacause alpha_0 is real  # (batch_size, 2)\n",
    "    num = torch.stack([b1, torch.zeros(batch_size,1)], dim=-1).squeeze(1)  # (batch_size, 2)\n",
    "   \n",
    "\n",
    "    frac = division_2_complex_numbers(num,denom)    # (batch_size, 2)\n",
    "    \n",
    "    x1_false = addition_complex_real_batch(sqrt_alpha ,- S) + sqrt_complex_batch(addition_batch(term,-frac))    # (batch_size, 2)\n",
    "    x2_false = addition_complex_real_batch(sqrt_alpha, - S) - sqrt_complex_batch(addition_batch(term,-frac))    # (batch_size, 2)\n",
    "    x3_false = addition_complex_real_batch(-sqrt_alpha, - S) + sqrt_complex_batch(addition_batch(term,frac))    # (batch_size, 2)\n",
    "    x4_false = addition_complex_real_batch(-sqrt_alpha,- S) - sqrt_complex_batch(addition_batch(term,frac))     # (batch_size, 2)\n",
    "    \n",
    "    # if alpha_0_nul == True\n",
    "    sqrt_inner1 = sqrt_batch((b2**2) / 4 - b0)        # complex \n",
    "\n",
    "    x1_true = addition_complex_real_batch(sqrt_complex_batch(addition_complex_real_batch(sqrt_inner1,-b2 / 2)),-S)\n",
    "    x2_true = addition_complex_real_batch(- sqrt_complex_batch(addition_complex_real_batch(sqrt_inner1,-b2 / 2)),-S)\n",
    "    x3_true = addition_complex_real_batch(sqrt_complex_batch(addition_complex_real_batch(- sqrt_inner1,-b2 / 2 )),-S)\n",
    "    x4_true = addition_complex_real_batch(- sqrt_complex_batch(addition_complex_real_batch(- sqrt_inner1,-b2 / 2 )),-S)\n",
    "    \n",
    "    result = torch.where(alpha_0==float('inf'),\n",
    "                         torch.stack([x1_true, x2_true, x3_true, x4_true]),torch.stack([x1_false, x2_false, x3_false, x4_false]))\n",
    "    \n",
    "    return result   # (4,batch_size, 2)\n",
    "\n",
    "a0  = torch.rand(batch_size, 1, dtype=torch.float64)\n",
    "a1  = torch.rand(batch_size, 1, dtype=torch.float64)  \n",
    "a2  = torch.rand(batch_size, 1, dtype=torch.float64)  \n",
    "a3  = torch.rand(batch_size, 1, dtype=torch.float64) \n",
    "a4  = torch.rand(batch_size, 1, dtype=torch.float64)  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have all the variables needed for the p3p so we start"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Storage of points : already done "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P1 = \n",
      " tensor([[-1.9540,  0.2069, -0.8956],\n",
      "        [-0.7383, -0.4089,  1.4930],\n",
      "        [-0.7537, -1.4189,  0.3761],\n",
      "        [ 1.5705,  1.9770, -0.4704],\n",
      "        [ 0.9455,  0.2458, -1.3549]], dtype=torch.float64)\n",
      "P2 = \n",
      " tensor([[ 1.2113, -1.7463,  1.3000],\n",
      "        [ 1.3310,  0.9893,  0.5098],\n",
      "        [ 1.8508, -0.0950, -1.2739],\n",
      "        [ 0.3550, -1.2609, -1.2266],\n",
      "        [-0.6543,  1.2507, -0.4034]], dtype=torch.float64)\n",
      "P3 = \n",
      " tensor([[ 1.1157, -0.6680,  0.6822],\n",
      "        [-1.6701, -0.2050,  1.6707],\n",
      "        [ 1.0510,  1.8721,  1.4427],\n",
      "        [ 1.0063,  0.4483, -0.0503],\n",
      "        [ 1.7563,  0.5605,  0.5006]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "print(\"P1 = \\n\", P1)\n",
    "print(\"P2 = \\n\", P2)\n",
    "print(\"P3 = \\n\", P3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Storage of the features vectors : done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 =  tensor([[-0.2725, -0.0289,  0.9617],\n",
      "        [-0.1610,  0.0892,  0.9829],\n",
      "        [-0.1289,  0.2426,  0.9615],\n",
      "        [ 0.2261, -0.2846,  0.9316],\n",
      "        [ 0.1274, -0.0331,  0.9913]], dtype=torch.float64)\n",
      "torch.Size([5, 3])\n",
      "f2 =  tensor([[ 0.2348,  0.3385,  0.9112],\n",
      "        [ 0.2321, -0.1725,  0.9573],\n",
      "        [ 0.2466,  0.0127,  0.9690],\n",
      "        [ 0.0483,  0.1717,  0.9840],\n",
      "        [-0.0998, -0.1907,  0.9766]], dtype=torch.float64)\n",
      "torch.Size([5, 3])\n",
      "f3 =  tensor([[ 0.2038,  0.1220,  0.9714],\n",
      "        [-0.3596,  0.0441,  0.9321],\n",
      "        [ 0.2086, -0.3716,  0.9046],\n",
      "        [ 0.1636, -0.0729,  0.9838],\n",
      "        [ 0.3028, -0.0966,  0.9481]], dtype=torch.float64)\n",
      "torch.Size([5, 3])\n"
     ]
    }
   ],
   "source": [
    "# we got featuresVect and we access the 3 values \n",
    "f1 = featuresVect[:,0,:]  # Access the first feature vector for each batch\n",
    "f2 = featuresVect[:,1,:]\n",
    "f3 = featuresVect[:,2,:]\n",
    "\n",
    "print(\"f1 = \", f1)\n",
    "print(f1.shape)  # (batsh_size,3)\n",
    "print(\"f2 = \", f2)\n",
    "print(f2.shape)  # (batsh_size,3)\n",
    "print(\"f3 = \", f3)\n",
    "print(f3.shape)  # (batsh_size,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Création of a solution variable : maximum 4 solutions  \n",
    "\n",
    "    Matrix (4,3,4)  \n",
    "    Each layer is a solution, for each leayer : first column stres the camera position matrix C (3,1) and the remaining 3 columns store the rotation matrix R (3,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "solutions = \n",
      " tensor([[[[1.5169e-311,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "         [[4.9407e-324, 4.9407e-324, 4.9407e-324, 4.9407e-324],\n",
      "          [4.9407e-324, 4.9407e-324, 4.9407e-324, 4.9407e-324],\n",
      "          [4.9407e-324, 4.9407e-324, 4.9407e-324, 4.9407e-324]],\n",
      "\n",
      "         [[4.9407e-324, 4.9407e-324, 4.9407e-324, 4.9407e-324],\n",
      "          [4.9407e-324, 4.9407e-324, 4.9407e-324, 4.9407e-324],\n",
      "          [4.9407e-324, 4.9407e-324, 4.9407e-324, 4.9407e-324]]],\n",
      "\n",
      "\n",
      "        [[[4.9407e-324, 4.9407e-324, 4.9407e-324, 4.9407e-324],\n",
      "          [4.9407e-324, 4.9407e-324, 4.9407e-324, 4.9407e-324],\n",
      "          [4.9407e-324, 4.9407e-324, 4.9407e-324, 4.9407e-324]],\n",
      "\n",
      "         [[4.9407e-324, 4.9407e-324, 4.9407e-324, 4.9407e-324],\n",
      "          [4.9407e-324, 4.9407e-324, 4.9407e-324, 4.9407e-324],\n",
      "          [4.9407e-324, 4.9407e-324, 4.9407e-324, 4.9407e-324]],\n",
      "\n",
      "         [[4.9407e-324, 4.9407e-324, 4.9407e-324, 4.9407e-324],\n",
      "          [4.9407e-324, 4.9407e-324, 4.9407e-324, 4.9407e-324],\n",
      "          [4.9407e-324, 4.9407e-324, 4.9407e-324, 4.9407e-324]],\n",
      "\n",
      "         [[4.9407e-324, 4.9407e-324, 4.9407e-324, 4.9407e-324],\n",
      "          [4.9407e-324, 4.9407e-324, 4.9407e-324, 4.9407e-324],\n",
      "          [4.9407e-324, 4.9407e-324, 4.9407e-324, 4.9407e-324]]],\n",
      "\n",
      "\n",
      "        [[[4.9407e-324, 4.9407e-324, 4.9407e-324, 4.9407e-324],\n",
      "          [4.9407e-324, 4.9407e-324, 4.9407e-324, 4.9407e-324],\n",
      "          [4.9407e-324, 4.9407e-324, 4.9407e-324, 4.9407e-324]],\n",
      "\n",
      "         [[4.9407e-324, 4.9407e-324, 4.9407e-324, 4.9407e-324],\n",
      "          [4.9407e-324, 4.9407e-324, 4.9407e-324, 4.9407e-324],\n",
      "          [4.9407e-324, 4.9407e-324, 4.9407e-324, 4.9407e-324]],\n",
      "\n",
      "         [[4.9407e-324, 4.9407e-324, 4.9407e-324, 4.9407e-324],\n",
      "          [4.9407e-324, 4.9407e-324, 4.9407e-324, 4.9407e-324],\n",
      "          [4.9407e-324, 4.9407e-324, 4.9407e-324, 4.9407e-324]],\n",
      "\n",
      "         [[4.9407e-324, 4.9407e-324, 4.9407e-324, 4.9407e-324],\n",
      "          [4.9407e-324, 4.9407e-324, 4.9407e-324, 4.9407e-324],\n",
      "          [4.9407e-324, 4.9407e-324, 4.9407e-324, 4.9407e-324]]],\n",
      "\n",
      "\n",
      "        [[[4.9407e-324, 4.9407e-324, 4.9407e-324, 4.9407e-324],\n",
      "          [4.9407e-324, 4.9407e-324, 4.9407e-324, 4.9407e-324],\n",
      "          [4.9407e-324, 4.9407e-324, 4.9407e-324, 4.9407e-324]],\n",
      "\n",
      "         [[4.9407e-324, 4.9407e-324, 4.9407e-324, 4.9407e-324],\n",
      "          [4.9407e-324, 4.9407e-324, 4.9407e-324, 4.9407e-324],\n",
      "          [4.9407e-324, 4.9407e-324, 4.9407e-324, 4.9407e-324]],\n",
      "\n",
      "         [[4.9407e-324, 4.9407e-324, 4.9407e-324, 4.9407e-324],\n",
      "          [4.9407e-324, 4.9407e-324, 4.9407e-324, 4.9407e-324],\n",
      "          [4.9407e-324, 4.9407e-324, 4.9407e-324, 4.9407e-324]],\n",
      "\n",
      "         [[4.9407e-324, 4.9407e-324, 4.9407e-324, 4.9407e-324],\n",
      "          [4.9407e-324, 4.9407e-324, 4.9407e-324, 4.9407e-324],\n",
      "          [4.9407e-324, 4.9407e-324, 4.9407e-324, 4.9407e-324]]],\n",
      "\n",
      "\n",
      "        [[[4.9407e-324, 4.9407e-324, 4.9407e-324, 4.9407e-324],\n",
      "          [4.9407e-324, 4.9407e-324, 4.9407e-324, 4.9407e-324],\n",
      "          [4.9407e-324, 4.9407e-324, 4.9407e-324, 4.9407e-324]],\n",
      "\n",
      "         [[4.9407e-324, 4.9407e-324, 4.9407e-324, 4.9407e-324],\n",
      "          [4.9407e-324, 4.9407e-324, 4.9407e-324, 4.9407e-324],\n",
      "          [4.9407e-324, 4.9407e-324, 4.9407e-324, 4.9407e-324]],\n",
      "\n",
      "         [[4.9407e-324, 4.9407e-324, 4.9407e-324, 4.9407e-324],\n",
      "          [4.9407e-324, 4.9407e-324, 4.9407e-324, 4.9407e-324],\n",
      "          [4.9407e-324, 4.9407e-324, 4.9407e-324, 4.9407e-324]],\n",
      "\n",
      "         [[4.9407e-324, 4.9407e-324, 4.9407e-324, 4.9407e-324],\n",
      "          [4.9407e-324, 4.9407e-324, 4.9407e-324, 4.9407e-324],\n",
      "          [4.9407e-324, 4.9407e-324, 4.9407e-324, 4.9407e-324]]]],\n",
      "       dtype=torch.float64)\n",
      "torch.Size([5, 4, 3, 4])\n"
     ]
    }
   ],
   "source": [
    "solutions = torch.empty((batch_size,4,3,4), dtype=torch.float64)\n",
    "\n",
    "print(\"solutions = \\n\", solutions)\n",
    "print(solutions.shape)  # (batch_size,4,3,4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Verification that the 3 points given are not collinear "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The points are not collinear, we can continue\n"
     ]
    }
   ],
   "source": [
    "# Test of non-collinearity\n",
    "v1 = P2 - P1 # (batch_size, 3)\n",
    " \n",
    "v2 = P3 - P1 # (batch_size, 3)\n",
    "\n",
    "norms = torch.norm(torch.cross(v1,v2, dim=1),dim = 1 )\n",
    "\n",
    "all_dif_zero = torch.all(norms != 0)  \n",
    "\n",
    "if not all_dif_zero:\n",
    "    print('\\nProblem: the points must not be collinear')\n",
    "else:\n",
    "    print('\\nThe points are not collinear, we can continue')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Creation of an orthonormal frame from f1, f2, f3 (the features vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tx =  tensor([[-0.2725, -0.0289,  0.9617],\n",
      "        [-0.1610,  0.0892,  0.9829],\n",
      "        [-0.1289,  0.2426,  0.9615],\n",
      "        [ 0.2261, -0.2846,  0.9316],\n",
      "        [ 0.1274, -0.0331,  0.9913]], dtype=torch.float64)\n",
      "torch.Size([5, 3])\n",
      "tz =  tensor([[-0.5898,  0.7947, -0.1433],\n",
      "        [ 0.5548,  0.8319,  0.0154],\n",
      "        [ 0.5190,  0.8427, -0.1431],\n",
      "        [-0.9218, -0.3717,  0.1101],\n",
      "        [ 0.5715, -0.8144, -0.1007]], dtype=torch.float64)\n",
      "torch.Size([5, 3])\n",
      "ty =  tensor([[ 0.7602,  0.6063,  0.2336],\n",
      "        [ 0.8163, -0.5478,  0.1834],\n",
      "        [ 0.8450, -0.4806,  0.2345],\n",
      "        [-0.3150,  0.8836,  0.3464],\n",
      "        [-0.8107, -0.5793,  0.0849]], dtype=torch.float64)\n",
      "torch.Size([5, 3])\n"
     ]
    }
   ],
   "source": [
    "# Calculation of vectors of the base τ = (C,tx,ty,tz)\n",
    "tx = f1     # (batch_size,3)\n",
    "print(\"tx = \", tx)\n",
    "print(tx.shape)  # (batch_size,3)\n",
    "\n",
    "tz = torch.cross(f1,f2,dim=1)/ torch.norm(torch.cross(f1,f2,dim=1),dim=1, keepdim=True) \n",
    "# (batch_size,3)\n",
    "print(\"tz = \", tz)\n",
    "print(tz.shape)  # (batch_size,3)\n",
    "\n",
    "ty = torch.cross(tz,tx,dim=1) # (batch_size,3)\n",
    "print(\"ty = \", ty)\n",
    "print(ty.shape)  # (batch_size,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. (bis) Creation of a transformation matrix T and expression of the f3 vector in this frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tx = \n",
      " tensor([[[-0.2725, -0.0289,  0.9617]],\n",
      "\n",
      "        [[-0.1610,  0.0892,  0.9829]],\n",
      "\n",
      "        [[-0.1289,  0.2426,  0.9615]],\n",
      "\n",
      "        [[ 0.2261, -0.2846,  0.9316]],\n",
      "\n",
      "        [[ 0.1274, -0.0331,  0.9913]]], dtype=torch.float64)\n",
      "ty = \n",
      " tensor([[[ 0.7602,  0.6063,  0.2336]],\n",
      "\n",
      "        [[ 0.8163, -0.5478,  0.1834]],\n",
      "\n",
      "        [[ 0.8450, -0.4806,  0.2345]],\n",
      "\n",
      "        [[-0.3150,  0.8836,  0.3464]],\n",
      "\n",
      "        [[-0.8107, -0.5793,  0.0849]]], dtype=torch.float64)\n",
      "tz = \n",
      " tensor([[[-0.5898,  0.7947, -0.1433]],\n",
      "\n",
      "        [[ 0.5548,  0.8319,  0.0154]],\n",
      "\n",
      "        [[ 0.5190,  0.8427, -0.1431]],\n",
      "\n",
      "        [[-0.9218, -0.3717,  0.1101]],\n",
      "\n",
      "        [[ 0.5715, -0.8144, -0.1007]]], dtype=torch.float64)\n",
      "T = \n",
      " tensor([[[-0.2725, -0.0289,  0.9617],\n",
      "         [ 0.7602,  0.6063,  0.2336],\n",
      "         [-0.5898,  0.7947, -0.1433]],\n",
      "\n",
      "        [[-0.1610,  0.0892,  0.9829],\n",
      "         [ 0.8163, -0.5478,  0.1834],\n",
      "         [ 0.5548,  0.8319,  0.0154]],\n",
      "\n",
      "        [[-0.1289,  0.2426,  0.9615],\n",
      "         [ 0.8450, -0.4806,  0.2345],\n",
      "         [ 0.5190,  0.8427, -0.1431]],\n",
      "\n",
      "        [[ 0.2261, -0.2846,  0.9316],\n",
      "         [-0.3150,  0.8836,  0.3464],\n",
      "         [-0.9218, -0.3717,  0.1101]],\n",
      "\n",
      "        [[ 0.1274, -0.0331,  0.9913],\n",
      "         [-0.8107, -0.5793,  0.0849],\n",
      "         [ 0.5715, -0.8144, -0.1007]]], dtype=torch.float64)\n",
      "torch.Size([5, 3, 3])\n",
      "f3_T = \n",
      " tensor([[[ 0.8751],\n",
      "         [ 0.4558],\n",
      "         [-0.1624]],\n",
      "\n",
      "        [[ 0.9780],\n",
      "         [-0.1467],\n",
      "         [-0.1484]],\n",
      "\n",
      "        [[ 0.7528],\n",
      "         [ 0.5670],\n",
      "         [-0.3343]],\n",
      "\n",
      "        [[ 0.9743],\n",
      "         [ 0.2249],\n",
      "         [-0.0154]],\n",
      "\n",
      "        [[ 0.9817],\n",
      "         [-0.1090],\n",
      "         [ 0.1563]]], dtype=torch.float64)\n",
      "torch.Size([5, 3, 1])\n"
     ]
    }
   ],
   "source": [
    "tx = torch.reshape(tx,(batch_size,1,3))   # (batch_size,1,3)\n",
    "print(\"tx = \\n\", tx)\n",
    "\n",
    "ty = torch.reshape(ty,(batch_size,1,3))  # (batch_size,1,3)\n",
    "print(\"ty = \\n\", ty)\n",
    "\n",
    "tz = torch.reshape(tz,(batch_size,1,3))  # (batch_size,1,3)\n",
    "print(\"tz = \\n\", tz)\n",
    "\n",
    "# Computation of the matrix T and the feature vector f3\n",
    "T = torch.cat((tx,ty,tz),dim = 1) # (3*3)\n",
    "print(\"T = \\n\", T)\n",
    "print(T.shape)  # (batch_size,3,3)\n",
    "\n",
    "\n",
    "f3_T = torch.matmul(T,f3.unsqueeze(-1)) # (\n",
    "print(\"f3_T = \\n\", f3_T)\n",
    "print(f3_T.shape)  # (batch_size,3,1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sing of the z-coordinate in f3_T give us the sign of teta, that we will need after "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.1624],\n",
      "        [-0.1484],\n",
      "        [-0.3343],\n",
      "        [-0.0154],\n",
      "        [ 0.1563]], dtype=torch.float64)\n",
      "f3_T_positif = \n",
      " tensor([[False],\n",
      "        [False],\n",
      "        [False],\n",
      "        [False],\n",
      "        [ True]])\n",
      "torch.Size([5, 1])\n"
     ]
    }
   ],
   "source": [
    "print(f3_T[:,2])\n",
    "f3_T_positif = f3_T[:,2] > 0        # (batch_size,1)\n",
    "\n",
    "print(\"f3_T_positif = \\n\", f3_T_positif)\n",
    "print(f3_T_positif.shape)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Change of frame is performed on the 3D points side, and the transformation matrix N is defined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nx = \n",
      " tensor([[[ 0.7329, -0.4522,  0.5084]],\n",
      "\n",
      "        [[ 0.7710,  0.5209, -0.3663]],\n",
      "\n",
      "        [[ 0.7762,  0.3946, -0.4918]],\n",
      "\n",
      "        [[-0.3433, -0.9146, -0.2136]],\n",
      "\n",
      "        [[-0.7563,  0.4751,  0.4498]]], dtype=torch.float64)\n",
      "torch.Size([5, 1, 3])\n",
      "ny = \n",
      " tensor([[[ 0.6098,  0.7679, -0.1961]],\n",
      "\n",
      "        [[-0.5896,  0.8013, -0.1013]],\n",
      "\n",
      "        [[ 0.0360,  0.7510,  0.6594]],\n",
      "\n",
      "        [[-0.0638, -0.2042,  0.9769]],\n",
      "\n",
      "        [[ 0.5415,  0.0687,  0.8379]]], dtype=torch.float64)\n",
      "nz = \n",
      " tensor([[[-0.3017,  0.4537,  0.8385]],\n",
      "\n",
      "        [[ 0.2408,  0.2941,  0.9249]],\n",
      "\n",
      "        [[ 0.6295, -0.5295,  0.5687]],\n",
      "\n",
      "        [[-0.9370,  0.3490,  0.0117]],\n",
      "\n",
      "        [[ 0.3671,  0.8773, -0.3092]]], dtype=torch.float64)\n",
      "N = \n",
      " tensor([[[ 0.7329, -0.4522,  0.5084],\n",
      "         [ 0.6098,  0.7679, -0.1961],\n",
      "         [-0.3017,  0.4537,  0.8385]],\n",
      "\n",
      "        [[ 0.7710,  0.5209, -0.3663],\n",
      "         [-0.5896,  0.8013, -0.1013],\n",
      "         [ 0.2408,  0.2941,  0.9249]],\n",
      "\n",
      "        [[ 0.7762,  0.3946, -0.4918],\n",
      "         [ 0.0360,  0.7510,  0.6594],\n",
      "         [ 0.6295, -0.5295,  0.5687]],\n",
      "\n",
      "        [[-0.3433, -0.9146, -0.2136],\n",
      "         [-0.0638, -0.2042,  0.9769],\n",
      "         [-0.9370,  0.3490,  0.0117]],\n",
      "\n",
      "        [[-0.7563,  0.4751,  0.4498],\n",
      "         [ 0.5415,  0.0687,  0.8379],\n",
      "         [ 0.3671,  0.8773, -0.3092]]], dtype=torch.float64)\n",
      "torch.Size([5, 3, 3])\n",
      "P3.shape =  torch.Size([5, 3])\n",
      "P3_n = \n",
      " tensor([[[ 3.4474e+00],\n",
      "         [ 8.9078e-01],\n",
      "         [-2.2204e-16]],\n",
      "\n",
      "        [[-6.7730e-01],\n",
      "         [ 6.9475e-01],\n",
      "         [ 0.0000e+00]],\n",
      "\n",
      "        [[ 2.1748e+00],\n",
      "         [ 3.2396e+00],\n",
      "         [ 1.1102e-16]],\n",
      "\n",
      "        [[ 1.5022e+00],\n",
      "         [ 7.5847e-01],\n",
      "         [-1.6480e-16]],\n",
      "\n",
      "        [[ 3.7085e-01],\n",
      "         [ 2.0153e+00],\n",
      "         [ 0.0000e+00]]], dtype=torch.float64)\n",
      "torch.Size([5, 3, 1])\n"
     ]
    }
   ],
   "source": [
    "# Calculation of vectors of the base η = (P1,nx,ny,nz)\n",
    "nx = (P2 - P1)/torch.norm(P2 - P1,dim=1,keepdim=True)      #(batch_size,3)\n",
    "nz = torch.cross(nx,P3-P1,dim=1)/torch.norm(torch.cross(nx,P3-P1,dim=1), dim=1, keepdim=True)  # (batch_size,3)\n",
    "ny = torch.cross(nz,nx,dim=1) # (batch_size,3)\n",
    "\n",
    "\n",
    "\n",
    "# Reshape the vectors to (1,3) for concatenation\n",
    "nx = torch.reshape(nx,(batch_size,1,3))  # (batch_size,1,3)\n",
    "ny = torch.reshape(ny,(batch_size,1,3))\n",
    "nz = torch.reshape(nz,(batch_size,1,3))\n",
    "\n",
    "print(\"nx = \\n\", nx)\n",
    "print(nx.shape)  # (1*3)\n",
    "print(\"ny = \\n\", ny)\n",
    "print(\"nz = \\n\", nz)\n",
    "\n",
    "# Computation of the matrix N and the world point P3\n",
    "N = torch.cat((nx,ny,nz),dim = 1) #  T's equivalent in the world coordinate system\n",
    "print(\"N = \\n\", N)\n",
    "print(N.shape)  # (batch_size,3,3)\n",
    "\n",
    "print(\"P3.shape = \", P3.shape)  # (batch_size,3)\n",
    "\n",
    "P3_n = torch.matmul(N,(P3-P1).unsqueeze(-1)) \n",
    "\n",
    "\n",
    "print(\"P3_n = \\n\", P3_n)\n",
    "print(P3_n.shape)  # (5,3,1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Definition of the variables for the following steps "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "phi1 =  tensor([[ -5.3889],\n",
      "        [ -6.5903],\n",
      "        [ -2.2519],\n",
      "        [-63.3762],\n",
      "        [  6.2817]], dtype=torch.float64)\n",
      "phi2 =  tensor([[ -2.8068],\n",
      "        [  0.9888],\n",
      "        [ -1.6962],\n",
      "        [-14.6287],\n",
      "        [ -0.6977]], dtype=torch.float64)\n",
      "p1 =  tensor([[ 3.4474],\n",
      "        [-0.6773],\n",
      "        [ 2.1748],\n",
      "        [ 1.5022],\n",
      "        [ 0.3708]], dtype=torch.float64)\n",
      "p2 =  tensor([[0.8908],\n",
      "        [0.6947],\n",
      "        [3.2396],\n",
      "        [0.7585],\n",
      "        [2.0153]], dtype=torch.float64)\n",
      "d12 =  tensor([[4.3192],\n",
      "        [2.6839],\n",
      "        [3.3554],\n",
      "        [3.5402],\n",
      "        [2.1153]], dtype=torch.float64)\n",
      "cosBeta =  tensor([[0.8025],\n",
      "        [0.8882],\n",
      "        [0.9031],\n",
      "        [0.8787],\n",
      "        [0.9617]], dtype=torch.float64)\n",
      "b =  tensor([[1.3451],\n",
      "        [1.9330],\n",
      "        [2.1026],\n",
      "        [1.8408],\n",
      "        [3.5064]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# Computation of phi1 et phi2 with 0=x, 1=y, 2=z\n",
    "phi1 = f3_T[:,0]/f3_T[:,2]  # (batch_size,1)\n",
    "phi2 = f3_T[:,1]/f3_T[:,2]  # (batch_size,1)\n",
    "print(\"phi1 = \", phi1)\n",
    "print(\"phi2 = \", phi2)\n",
    "\n",
    "# Extraction of p1 and p2 from P3_eta\n",
    "p1 = P3_n[:,0] #x  # (batch_size,3)\n",
    "p2 = P3_n[:,1] #y  # (batch_size,3)\n",
    "print(\"p1 = \", p1)\n",
    "print(\"p2 = \", p2)\n",
    "\n",
    "# Computation of d12\n",
    "d12 = torch.norm(P2-P1,dim=1, keepdim=True)  # (batch_size,1)\n",
    "print(\"d12 = \", d12)\n",
    "\n",
    "# Computation of b = cot(beta)\n",
    "cosBeta =( torch.sum(f1*f2,dim=1)/(torch.norm(f1,dim=1)*torch.norm(f2,dim=1)) ).unsqueeze(-1)  # tensor.dot(a,b) <=> tensor.sum(a*b)   # (batch_size,1)\n",
    "print(\"cosBeta = \", cosBeta)  \n",
    "\n",
    "b = torch.sqrt(1/(1-cosBeta**2)-1)\n",
    "\n",
    "b = torch.where(cosBeta < 0, -b, b)  # If cosBeta < 0, then b = -b    # (batch_size,1)\n",
    "print(\"b = \", b)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Calculation of the coefficients of the polynomial "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a4 =  tensor([[  -23.8744],\n",
      "        [  -10.5794],\n",
      "        [ -985.6722],\n",
      "        [-1400.3722],\n",
      "        [ -675.4291]], dtype=torch.float64)\n",
      "torch.Size([5, 1])\n",
      "a3 =  tensor([[  -19.4377],\n",
      "        [   18.6107],\n",
      "        [  988.5070],\n",
      "        [-1641.4781],\n",
      "        [  332.3041]], dtype=torch.float64)\n",
      "a3.shape =  torch.Size([5, 1])\n",
      "a2 =  tensor([[  -7.6106],\n",
      "        [ -10.3877],\n",
      "        [-159.5269],\n",
      "        [ 867.7973],\n",
      "        [ 205.9887]], dtype=torch.float64)\n",
      "torch.Size([5, 1])\n",
      "a1 =  tensor([[-3.4573e+00],\n",
      "        [ 1.2793e+00],\n",
      "        [-6.2612e+02],\n",
      "        [ 1.6169e+03],\n",
      "        [-2.3022e+02]], dtype=torch.float64)\n",
      "torch.Size([5, 1])\n",
      "a0 =  tensor([[-1.9078e-01],\n",
      "        [ 3.6290e-01],\n",
      "        [ 5.5998e+02],\n",
      "        [ 5.0196e+02],\n",
      "        [ 2.3435e+02]], dtype=torch.float64)\n",
      "torch.Size([5, 1])\n"
     ]
    }
   ],
   "source": [
    "a4 = - phi2**2 * p2**4 - phi1**2 * p2**4 - p2**4\n",
    "a3 = 2 * p2**3 * d12 * b + 2 * phi2**2 * p2**3 * d12 * b - 2 * phi1 * phi2 * p2**3 * d12\n",
    "a2 = - phi2**2 * p1**2 * p2**2 - phi2**2 * p2**2 * d12**2 * b**2 - phi2**2 * p2**2 * d12**2 + phi2**2 * p2**4 + phi1**2 * p2 **4 + 2 * p1 * p2**2 * d12 + 2 * phi1 * phi2 * p1 * p2**2 * d12 * b - phi1**2 * p1**2 * p2**2 + 2 * phi2**2 * p1 * p2**2 * d12 - p2**2 * d12**2 * b**2 - 2 * p1**2 * p2**2\n",
    "a1 = 2 * p1**2 * p2 * d12 * b + 2 * phi1 * phi2 * p2**3 * d12 - 2 * phi2**2 * p2**3 * d12 * b - 2 * p1 * p2 * d12**2 * b\n",
    "a0 = - 2 * phi1 * phi2 * p1 * p2**2 * d12 * b + phi2**2 * p2**2 * d12**2 + 2 * p1**3 * d12 - p1**2 * d12**2 + phi2**2 * p1**2 * p2**2 - p1**4 - 2 * phi2**2 * p1 * p2**2 * d12 + phi1**2 * p1**2 * p2**2 + phi2**2 * p2**2 * d12**2 * b**2\n",
    "\n",
    "print(\"a4 = \", a4)\n",
    "print(a4.shape)  # (batch_size,1)\n",
    "print(\"a3 = \", a3)\n",
    "print(\"a3.shape = \", a3.shape)  # (batch_size,1)\n",
    "print(\"a2 = \", a2)\n",
    "print(a2.shape)  # (batch_size,1)\n",
    "print(\"a1 = \", a1)\n",
    "print(a1.shape)  # (batch_size,1)\n",
    "print(\"a0 = \", a0)\n",
    "print(a0.shape)  # (batch_size,1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. Recovery of the polynomial roots cos (teta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roots = \n",
      " tensor([[[-0.0562,  0.4436],\n",
      "         [ 0.5801,  0.2031],\n",
      "         [ 0.4810,  0.7656],\n",
      "         [ 0.9922,  0.0000],\n",
      "         [ 0.2305,  0.6305]],\n",
      "\n",
      "        [[-0.0562, -0.4436],\n",
      "         [ 0.5801, -0.2031],\n",
      "         [ 0.4810, -0.7656],\n",
      "         [-0.9886,  0.0000],\n",
      "         [ 0.2305, -0.6305]],\n",
      "\n",
      "        [[-0.0625,  0.0000],\n",
      "         [ 0.7243,  0.0000],\n",
      "         [ 0.8543,  0.0000],\n",
      "         [-0.5879,  0.1408],\n",
      "         [ 0.8931,  0.0000]],\n",
      "\n",
      "        [[-0.6393, -0.0000],\n",
      "         [-0.1254, -0.0000],\n",
      "         [-0.8135, -0.0000],\n",
      "         [-0.5879, -0.1408],\n",
      "         [-0.8621, -0.0000]]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "from torch import vmap\n",
    "\n",
    "# Computation of the roots\n",
    "roots = polynomial_root_calculation_4th_degree_ferrari(a0,a1,a2,a3,a4) # (batch_size,4)\n",
    "\n",
    "print(\"roots = \\n\", roots)  # list of tensor (for complex numbers)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. For each solution : computation of the camera position and rotation matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cos_teta = \n",
      " tensor([[-0.0562],\n",
      "        [ 0.5801],\n",
      "        [ 0.4810],\n",
      "        [ 0.9922],\n",
      "        [ 0.2305]], dtype=torch.float64)\n",
      "sin_teta = \n",
      " tensor([[ 0.9984],\n",
      "        [ 0.8145],\n",
      "        [ 0.8767],\n",
      "        [ 0.1246],\n",
      "        [-0.9731]], dtype=torch.float64)\n",
      "cos_teta = \n",
      " tensor([[-0.0562],\n",
      "        [ 0.5801],\n",
      "        [ 0.4810],\n",
      "        [-0.9886],\n",
      "        [ 0.2305]], dtype=torch.float64)\n",
      "sin_teta = \n",
      " tensor([[ 0.9984],\n",
      "        [ 0.8145],\n",
      "        [ 0.8767],\n",
      "        [ 0.1506],\n",
      "        [-0.9731]], dtype=torch.float64)\n",
      "cos_teta = \n",
      " tensor([[-0.0625],\n",
      "        [ 0.7243],\n",
      "        [ 0.8543],\n",
      "        [-0.5879],\n",
      "        [ 0.8931]], dtype=torch.float64)\n",
      "sin_teta = \n",
      " tensor([[ 0.9980],\n",
      "        [ 0.6895],\n",
      "        [ 0.5198],\n",
      "        [ 0.8089],\n",
      "        [-0.4498]], dtype=torch.float64)\n",
      "cos_teta = \n",
      " tensor([[-0.6393],\n",
      "        [-0.1254],\n",
      "        [-0.8135],\n",
      "        [-0.5879],\n",
      "        [-0.8621]], dtype=torch.float64)\n",
      "sin_teta = \n",
      " tensor([[ 0.7690],\n",
      "        [ 0.9921],\n",
      "        [ 0.5816],\n",
      "        [ 0.8089],\n",
      "        [-0.5068]], dtype=torch.float64)\n",
      "solutions = \n",
      " tensor([[[[ 2.1078e-03,  1.0000e+00, -2.7419e-03, -2.6027e-04],\n",
      "          [ 4.0056e-02, -2.7436e-03, -9.9997e-01, -6.5965e-03],\n",
      "          [ 6.0039e+00, -2.4218e-04,  6.5972e-03, -9.9998e-01]],\n",
      "\n",
      "         [[ 2.1078e-03,  1.0000e+00, -2.7419e-03, -2.6028e-04],\n",
      "          [ 4.0056e-02, -2.7436e-03, -9.9997e-01, -6.5965e-03],\n",
      "          [ 6.0039e+00, -2.4218e-04,  6.5972e-03, -9.9998e-01]],\n",
      "\n",
      "         [[-7.3766e-09,  1.0000e+00,  1.0956e-08,  8.7354e-10],\n",
      "          [-1.6014e-07,  1.0956e-08, -1.0000e+00,  2.6384e-08],\n",
      "          [ 6.0000e+00,  8.7354e-10, -2.6384e-08, -1.0000e+00]],\n",
      "\n",
      "         [[-2.6970e+00, -6.7624e-02, -2.2224e-01,  9.7264e-01],\n",
      "          [ 3.8921e-01,  2.7088e-01, -9.4235e-01, -1.9649e-01],\n",
      "          [-7.7976e-01,  9.6023e-01,  2.5018e-01,  1.2393e-01]]],\n",
      "\n",
      "\n",
      "        [[[-2.3502e+00,  8.1571e-01,  1.9111e-01,  5.4597e-01],\n",
      "          [ 1.3466e+00,  4.1530e-01, -8.5049e-01, -3.2279e-01],\n",
      "          [ 4.4739e+00,  4.0266e-01,  4.9005e-01, -7.7312e-01]],\n",
      "\n",
      "         [[-2.3502e+00,  8.1571e-01,  1.9111e-01,  5.4597e-01],\n",
      "          [ 1.3466e+00,  4.1530e-01, -8.5049e-01, -3.2279e-01],\n",
      "          [ 4.4739e+00,  4.0266e-01,  4.9005e-01, -7.7312e-01]],\n",
      "\n",
      "         [[ 1.1831e+00,  1.0584e-02,  6.7764e-01,  7.3532e-01],\n",
      "          [ 7.8808e-01,  3.9026e-01, -6.7984e-01,  6.2089e-01],\n",
      "          [ 5.3354e-01,  9.2064e-01,  2.8039e-01, -2.7165e-01]],\n",
      "\n",
      "         [[ 3.9427e-09,  1.0000e+00, -5.3259e-10, -8.1739e-10],\n",
      "          [-5.2567e-09, -5.3259e-10, -1.0000e+00,  1.0841e-09],\n",
      "          [ 6.0000e+00, -8.1739e-10, -1.0841e-09, -1.0000e+00]]],\n",
      "\n",
      "\n",
      "        [[[-8.9708e-01,  9.4788e-01, -2.2335e-01,  2.2725e-01],\n",
      "          [-2.5319e+00, -3.1058e-01, -8.0693e-01,  5.0240e-01],\n",
      "          [ 3.5858e+00,  7.1160e-02, -5.4679e-01, -8.3424e-01]],\n",
      "\n",
      "         [[-8.9708e-01,  9.4788e-01, -2.2335e-01,  2.2725e-01],\n",
      "          [-2.5319e+00, -3.1058e-01, -8.0693e-01,  5.0240e-01],\n",
      "          [ 3.5858e+00,  7.1160e-02, -5.4679e-01, -8.3424e-01]],\n",
      "\n",
      "         [[ 1.0174e-09,  1.0000e+00, -1.0077e-09, -5.0272e-11],\n",
      "          [-1.5377e-08, -1.0077e-09, -1.0000e+00,  2.3665e-09],\n",
      "          [ 6.0000e+00, -5.0272e-11, -2.3665e-09, -1.0000e+00]],\n",
      "\n",
      "         [[ 3.8440e+00, -2.2580e-01, -6.2084e-01, -7.5071e-01],\n",
      "          [-9.9852e-01,  8.4927e-01, -5.0297e-01,  1.6051e-01],\n",
      "          [-2.5231e+00, -4.7724e-01, -6.0131e-01,  6.4083e-01]]],\n",
      "\n",
      "\n",
      "        [[[-5.6487e-07,  1.0000e+00, -1.9155e-08,  8.1504e-08],\n",
      "          [ 2.3271e-07, -1.9155e-08, -1.0000e+00, -3.1246e-08],\n",
      "          [ 6.0000e+00,  8.1504e-08,  3.1246e-08, -1.0000e+00]],\n",
      "\n",
      "         [[-2.6852e-01, -7.2801e-01, -6.3909e-01,  2.4812e-01],\n",
      "          [-2.3171e-02,  6.3744e-01, -7.6423e-01, -9.8153e-02],\n",
      "          [-7.3556e+00,  2.5235e-01,  8.6705e-02,  9.6374e-01]],\n",
      "\n",
      "         [[ 1.2356e+00, -3.4836e-01, -8.6442e-01, -3.6252e-01],\n",
      "          [ 4.7153e-02, -2.4305e-01,  4.5681e-01, -8.5571e-01],\n",
      "          [-6.2663e-01,  9.0530e-01, -2.0998e-01, -3.6924e-01]],\n",
      "\n",
      "         [[ 1.2356e+00, -3.4836e-01, -8.6443e-01, -3.6252e-01],\n",
      "          [ 4.7153e-02, -2.4305e-01,  4.5681e-01, -8.5571e-01],\n",
      "          [-6.2663e-01,  9.0530e-01, -2.0998e-01, -3.6924e-01]]],\n",
      "\n",
      "\n",
      "        [[[-2.0288e+00,  4.0796e-01, -5.5431e-01,  7.2547e-01],\n",
      "          [ 1.2602e+00, -6.3022e-01, -7.4590e-01, -2.1553e-01],\n",
      "          [ 7.2294e-01,  6.6060e-01, -3.6928e-01, -6.5364e-01]],\n",
      "\n",
      "         [[-2.0288e+00,  4.0796e-01, -5.5431e-01,  7.2547e-01],\n",
      "          [ 1.2602e+00, -6.3022e-01, -7.4590e-01, -2.1553e-01],\n",
      "          [ 7.2294e-01,  6.6060e-01, -3.6928e-01, -6.5364e-01]],\n",
      "\n",
      "         [[-3.0252e-07,  1.0000e+00, -2.7302e-08,  4.0839e-08],\n",
      "          [-2.1826e-07, -2.7302e-08, -1.0000e+00,  3.3347e-08],\n",
      "          [ 6.0000e+00,  4.0839e-08, -3.3347e-08, -1.0000e+00]],\n",
      "\n",
      "         [[ 5.2003e-01,  7.9403e-01,  6.0783e-01,  7.8656e-03],\n",
      "          [-3.0412e+00, -3.9920e-01,  5.1164e-01,  7.6083e-01],\n",
      "          [-4.8114e+00,  4.5843e-01, -6.0726e-01,  6.4890e-01]]]],\n",
      "       dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# For each solution of the polynomial\n",
    "for i in range(4):\n",
    "  # Computation of trigonometrics forms\n",
    "  cos_teta = (roots[i,:,0]).unsqueeze(-1) # real part of the root (batch_size,1)\n",
    "\n",
    "  print(\"cos_teta = \\n\", cos_teta)   # (batch_size,1)\n",
    "  sin_teta = torch.where(f3_T_positif,-torch.sqrt(1-cos_teta**2),torch.sqrt(1-cos_teta**2))\n",
    "  print(\"sin_teta = \\n\", sin_teta) # (batch_size,1)\n",
    "\n",
    "  cot_alpha = ((phi1/phi2)*p1 + cos_teta*p2 -d12*b )/ ((phi1/phi2)*cos_teta* p2 - p1 + d12)\n",
    "\n",
    "  sin_alpha = torch.sqrt(1/(cot_alpha**2+1))\n",
    "  cos_alpha = torch.sqrt(1-sin_alpha**2)\n",
    "  cos_alpha = torch.where(cot_alpha < 0, -cos_alpha, cos_alpha)  \n",
    "\n",
    "  # Computation of the intermediate rotation's matrixs\n",
    "  C_estimate = torch.stack([d12*cos_alpha*(sin_alpha*b + cos_alpha), d12*sin_alpha*cos_teta*(sin_alpha*b+cos_alpha), d12*sin_alpha*sin_teta*(sin_alpha*b+cos_alpha)],dim=1)  # (batch_size,3,1)\n",
    "  # (batch_size,3,1)\n",
    "\n",
    "  Q_row1 = torch.stack([-cos_alpha, -sin_alpha*cos_teta, -sin_alpha*sin_teta], dim=-1)  \n",
    "  Q_row2 = torch.stack([sin_alpha, -cos_alpha*cos_teta, -cos_alpha*sin_teta],dim=-1)\n",
    "  Q_row3 = torch.stack([0*sin_teta, -sin_teta, cos_teta], dim=-1)\n",
    "  Q = torch.stack([Q_row1,Q_row2 ,Q_row3],dim=1).squeeze(2)  # (batch_size,3*3)\n",
    "  \n",
    "\n",
    "\n",
    "  # Computation of the absolute camera center\n",
    "  C_estimate = P1.unsqueeze(-1) + torch.matmul(torch.transpose(N, 1,2), C_estimate) # (batch_size,3,1)\n",
    " \n",
    "  \n",
    "\n",
    "  # Computation of the orientation matrix\n",
    "  R_estimate = torch.matmul(torch.matmul(torch.transpose(N,1,2),torch.transpose(Q, 1,2)),T)   # (batch_size,3,3)\n",
    "\n",
    "  # Adding C and R to the solutions\n",
    "  solutions[:,i,:,:1]= C_estimate\n",
    "  solutions[:,i,:,1:] = R_estimate\n",
    "\n",
    "print(\"solutions = \\n\", solutions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "solutions = \n",
      " tensor([[[[ 2.1078e-03,  1.0000e+00, -2.7419e-03, -2.6027e-04],\n",
      "          [ 4.0056e-02, -2.7436e-03, -9.9997e-01, -6.5965e-03],\n",
      "          [ 6.0039e+00, -2.4218e-04,  6.5972e-03, -9.9998e-01]],\n",
      "\n",
      "         [[ 2.1078e-03,  1.0000e+00, -2.7419e-03, -2.6028e-04],\n",
      "          [ 4.0056e-02, -2.7436e-03, -9.9997e-01, -6.5965e-03],\n",
      "          [ 6.0039e+00, -2.4218e-04,  6.5972e-03, -9.9998e-01]],\n",
      "\n",
      "         [[-7.3766e-09,  1.0000e+00,  1.0956e-08,  8.7354e-10],\n",
      "          [-1.6014e-07,  1.0956e-08, -1.0000e+00,  2.6384e-08],\n",
      "          [ 6.0000e+00,  8.7354e-10, -2.6384e-08, -1.0000e+00]],\n",
      "\n",
      "         [[-2.6970e+00, -6.7624e-02, -2.2224e-01,  9.7264e-01],\n",
      "          [ 3.8921e-01,  2.7088e-01, -9.4235e-01, -1.9649e-01],\n",
      "          [-7.7976e-01,  9.6023e-01,  2.5018e-01,  1.2393e-01]]],\n",
      "\n",
      "\n",
      "        [[[-2.3502e+00,  8.1571e-01,  1.9111e-01,  5.4597e-01],\n",
      "          [ 1.3466e+00,  4.1530e-01, -8.5049e-01, -3.2279e-01],\n",
      "          [ 4.4739e+00,  4.0266e-01,  4.9005e-01, -7.7312e-01]],\n",
      "\n",
      "         [[-2.3502e+00,  8.1571e-01,  1.9111e-01,  5.4597e-01],\n",
      "          [ 1.3466e+00,  4.1530e-01, -8.5049e-01, -3.2279e-01],\n",
      "          [ 4.4739e+00,  4.0266e-01,  4.9005e-01, -7.7312e-01]],\n",
      "\n",
      "         [[ 1.1831e+00,  1.0584e-02,  6.7764e-01,  7.3532e-01],\n",
      "          [ 7.8808e-01,  3.9026e-01, -6.7984e-01,  6.2089e-01],\n",
      "          [ 5.3354e-01,  9.2064e-01,  2.8039e-01, -2.7165e-01]],\n",
      "\n",
      "         [[ 3.9427e-09,  1.0000e+00, -5.3259e-10, -8.1739e-10],\n",
      "          [-5.2567e-09, -5.3259e-10, -1.0000e+00,  1.0841e-09],\n",
      "          [ 6.0000e+00, -8.1739e-10, -1.0841e-09, -1.0000e+00]]],\n",
      "\n",
      "\n",
      "        [[[-8.9708e-01,  9.4788e-01, -2.2335e-01,  2.2725e-01],\n",
      "          [-2.5319e+00, -3.1058e-01, -8.0693e-01,  5.0240e-01],\n",
      "          [ 3.5858e+00,  7.1160e-02, -5.4679e-01, -8.3424e-01]],\n",
      "\n",
      "         [[-8.9708e-01,  9.4788e-01, -2.2335e-01,  2.2725e-01],\n",
      "          [-2.5319e+00, -3.1058e-01, -8.0693e-01,  5.0240e-01],\n",
      "          [ 3.5858e+00,  7.1160e-02, -5.4679e-01, -8.3424e-01]],\n",
      "\n",
      "         [[ 1.0174e-09,  1.0000e+00, -1.0077e-09, -5.0272e-11],\n",
      "          [-1.5377e-08, -1.0077e-09, -1.0000e+00,  2.3665e-09],\n",
      "          [ 6.0000e+00, -5.0272e-11, -2.3665e-09, -1.0000e+00]],\n",
      "\n",
      "         [[ 3.8440e+00, -2.2580e-01, -6.2084e-01, -7.5071e-01],\n",
      "          [-9.9852e-01,  8.4927e-01, -5.0297e-01,  1.6051e-01],\n",
      "          [-2.5231e+00, -4.7724e-01, -6.0131e-01,  6.4083e-01]]],\n",
      "\n",
      "\n",
      "        [[[-5.6487e-07,  1.0000e+00, -1.9155e-08,  8.1504e-08],\n",
      "          [ 2.3271e-07, -1.9155e-08, -1.0000e+00, -3.1246e-08],\n",
      "          [ 6.0000e+00,  8.1504e-08,  3.1246e-08, -1.0000e+00]],\n",
      "\n",
      "         [[-2.6852e-01, -7.2801e-01, -6.3909e-01,  2.4812e-01],\n",
      "          [-2.3171e-02,  6.3744e-01, -7.6423e-01, -9.8153e-02],\n",
      "          [-7.3556e+00,  2.5235e-01,  8.6705e-02,  9.6374e-01]],\n",
      "\n",
      "         [[ 1.2356e+00, -3.4836e-01, -8.6442e-01, -3.6252e-01],\n",
      "          [ 4.7153e-02, -2.4305e-01,  4.5681e-01, -8.5571e-01],\n",
      "          [-6.2663e-01,  9.0530e-01, -2.0998e-01, -3.6924e-01]],\n",
      "\n",
      "         [[ 1.2356e+00, -3.4836e-01, -8.6443e-01, -3.6252e-01],\n",
      "          [ 4.7153e-02, -2.4305e-01,  4.5681e-01, -8.5571e-01],\n",
      "          [-6.2663e-01,  9.0530e-01, -2.0998e-01, -3.6924e-01]]],\n",
      "\n",
      "\n",
      "        [[[-2.0288e+00,  4.0796e-01, -5.5431e-01,  7.2547e-01],\n",
      "          [ 1.2602e+00, -6.3022e-01, -7.4590e-01, -2.1553e-01],\n",
      "          [ 7.2294e-01,  6.6060e-01, -3.6928e-01, -6.5364e-01]],\n",
      "\n",
      "         [[-2.0288e+00,  4.0796e-01, -5.5431e-01,  7.2547e-01],\n",
      "          [ 1.2602e+00, -6.3022e-01, -7.4590e-01, -2.1553e-01],\n",
      "          [ 7.2294e-01,  6.6060e-01, -3.6928e-01, -6.5364e-01]],\n",
      "\n",
      "         [[-3.0252e-07,  1.0000e+00, -2.7302e-08,  4.0839e-08],\n",
      "          [-2.1826e-07, -2.7302e-08, -1.0000e+00,  3.3347e-08],\n",
      "          [ 6.0000e+00,  4.0839e-08, -3.3347e-08, -1.0000e+00]],\n",
      "\n",
      "         [[ 5.2003e-01,  7.9403e-01,  6.0783e-01,  7.8656e-03],\n",
      "          [-3.0412e+00, -3.9920e-01,  5.1164e-01,  7.6083e-01],\n",
      "          [-4.8114e+00,  4.5843e-01, -6.0726e-01,  6.4890e-01]]]],\n",
      "       dtype=torch.float64)\n",
      "torch.Size([5, 4, 3, 4])\n"
     ]
    }
   ],
   "source": [
    "print(\"solutions = \\n\", solutions)\n",
    "print(solutions.shape)  # (batch_size,4,3,4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11. Reprojection of points in 2D from the newly estimated matrices to verify the estimation error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p1 =  tensor([[[ 93.3048],\n",
      "         [215.9945]],\n",
      "\n",
      "        [[188.9548],\n",
      "         [312.5749]],\n",
      "\n",
      "        [[212.7924],\n",
      "         [441.8411]],\n",
      "\n",
      "        [[514.1729],\n",
      "         [ -4.4355]],\n",
      "\n",
      "        [[422.8428],\n",
      "         [213.2618]]], dtype=torch.float64)\n",
      "torch.Size([5, 2, 1])\n",
      "p2 =  tensor([[[526.1874],\n",
      "         [537.2432]],\n",
      "\n",
      "        [[513.9385],\n",
      "         [ 95.8474]],\n",
      "\n",
      "        [[523.5503],\n",
      "         [250.4444]],\n",
      "\n",
      "        [[359.3027],\n",
      "         [379.5817]],\n",
      "\n",
      "        [[238.2580],\n",
      "         [ 83.7410]]], dtype=torch.float64)\n",
      "p3 =  tensor([[[487.8371],\n",
      "         [340.4956]],\n",
      "\n",
      "        [[ 11.3889],\n",
      "         [277.8800]],\n",
      "\n",
      "        [[504.5014],\n",
      "         [-88.6267]],\n",
      "\n",
      "        [[453.0589],\n",
      "         [180.7295]],\n",
      "\n",
      "        [[575.4905],\n",
      "         [158.4682]]], dtype=torch.float64)\n",
      "p4 =  tensor([[[443.7396],\n",
      "         [ 50.6752]],\n",
      "\n",
      "        [[368.4463],\n",
      "         [126.6685]],\n",
      "\n",
      "        [[197.1243],\n",
      "         [136.6137]],\n",
      "\n",
      "        [[424.8888],\n",
      "         [ 44.1191]],\n",
      "\n",
      "        [[488.4128],\n",
      "         [423.4719]]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "def projection3D2D(point3D,C,R,A) :\n",
    "  # 3D point = [ Xw, Yw, Zw ]'   (1*3)\n",
    "  # T : camera translation matrix : (3*1)\n",
    "  # R : camera rotation matrix : (3*3)\n",
    "  # A : intraseca matrix of the camera : (3*3)\n",
    "  # Output : return the coordonates of the point in 2D \n",
    "\n",
    "  PI = torch.cat((torch.eye(3, dtype=torch.float64),torch.zeros((3,1), dtype=torch.float64)),dim=1)  # (3*4)\n",
    "\n",
    "  Rt = torch.cat((R,C),dim=1)               # (3*4)\n",
    "  Rt = torch.cat((Rt,torch.tensor([[0,0,0,1]], dtype=torch.float64)),dim=0)   # (4*4)\n",
    "\n",
    "  point3D_bis = torch.cat((torch.reshape(point3D,(3,1)),torch.tensor([[1]],dtype=torch.float64)),dim=0)   #(4*1)\n",
    "  \n",
    "  point2D = torch.tensordot(torch.tensordot(torch.tensordot(A,PI,dims=1),Rt,dims=1),point3D_bis,dims=1)  # 2D point = [u, v, w] (3*1)\n",
    "  point2D = point2D / point2D[2]        # 2D point = [u, v, 1] (3*1)\n",
    "  return point2D[:2]\n",
    "\n",
    "\n",
    "C_transpose = C.unsqueeze(-1) # (batch_size,3,1)\n",
    "\n",
    "p1 = vmap(projection3D2D)(P1,C_transpose,R,A)   # (batch_size,2,1)\n",
    "print(\"p1 = \", p1)\n",
    "print(p1.shape)  # (batch_size,2,1)\n",
    "p2 = vmap(projection3D2D)(points3D[1],C_transpose,R,A)\n",
    "print(\"p2 = \", p2)\n",
    "p3 = vmap(projection3D2D)(points3D[2],C_transpose,R,A)\n",
    "print(\"p3 = \", p3)\n",
    "p4 = vmap(projection3D2D)(P4,C_transpose,R,A)\n",
    "print(\"p4 = \", p4)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12. Calculation of errors = distance between the 2D points estimated from the found rotation and position matrices and the 2D points from the initial matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "============ Batch number :  1 =====================\n",
      "------------ Solution n° :  1 ----------------\n",
      "R = \n",
      " tensor([[ 1.0000e+00, -2.7419e-03, -2.6027e-04],\n",
      "        [-2.7436e-03, -9.9997e-01, -6.5965e-03],\n",
      "        [-2.4218e-04,  6.5972e-03, -9.9998e-01]], dtype=torch.float64)\n",
      "C = \n",
      " tensor([[2.1078e-03],\n",
      "        [4.0056e-02],\n",
      "        [6.0039e+00]], dtype=torch.float64)\n",
      "------------ Solution n° :  2 ----------------\n",
      "R = \n",
      " tensor([[ 1.0000e+00, -2.7419e-03, -2.6028e-04],\n",
      "        [-2.7436e-03, -9.9997e-01, -6.5965e-03],\n",
      "        [-2.4218e-04,  6.5972e-03, -9.9998e-01]], dtype=torch.float64)\n",
      "C = \n",
      " tensor([[2.1078e-03],\n",
      "        [4.0056e-02],\n",
      "        [6.0039e+00]], dtype=torch.float64)\n",
      "------------ Solution n° :  3 ----------------\n",
      "R = \n",
      " tensor([[ 1.0000e+00,  1.0956e-08,  8.7354e-10],\n",
      "        [ 1.0956e-08, -1.0000e+00,  2.6384e-08],\n",
      "        [ 8.7354e-10, -2.6384e-08, -1.0000e+00]], dtype=torch.float64)\n",
      "C = \n",
      " tensor([[-7.3766e-09],\n",
      "        [-1.6014e-07],\n",
      "        [ 6.0000e+00]], dtype=torch.float64)\n",
      "------------ Solution n° :  4 ----------------\n",
      "R = \n",
      " tensor([[-0.0676, -0.2222,  0.9726],\n",
      "        [ 0.2709, -0.9423, -0.1965],\n",
      "        [ 0.9602,  0.2502,  0.1239]], dtype=torch.float64)\n",
      "C = \n",
      " tensor([[-2.6970],\n",
      "        [ 0.3892],\n",
      "        [-0.7798]], dtype=torch.float64)\n",
      "\n",
      "------------ Best solution : ----------------\n",
      "Solution n° : 3 \n",
      "\n",
      "R estimé = \n",
      " tensor([[ 1.0000e+00,  1.0956e-08,  8.7354e-10],\n",
      "        [ 1.0956e-08, -1.0000e+00,  2.6384e-08],\n",
      "        [ 8.7354e-10, -2.6384e-08, -1.0000e+00]], dtype=torch.float64) \n",
      "\n",
      "C estimé = \n",
      " tensor([[-7.3766e-09],\n",
      "        [-1.6014e-07],\n",
      "        [ 6.0000e+00]], dtype=torch.float64) \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "============ Batch number :  2 =====================\n",
      "------------ Solution n° :  1 ----------------\n",
      "R = \n",
      " tensor([[ 0.8157,  0.1911,  0.5460],\n",
      "        [ 0.4153, -0.8505, -0.3228],\n",
      "        [ 0.4027,  0.4900, -0.7731]], dtype=torch.float64)\n",
      "C = \n",
      " tensor([[-2.3502],\n",
      "        [ 1.3466],\n",
      "        [ 4.4739]], dtype=torch.float64)\n",
      "------------ Solution n° :  2 ----------------\n",
      "R = \n",
      " tensor([[ 0.8157,  0.1911,  0.5460],\n",
      "        [ 0.4153, -0.8505, -0.3228],\n",
      "        [ 0.4027,  0.4900, -0.7731]], dtype=torch.float64)\n",
      "C = \n",
      " tensor([[-2.3502],\n",
      "        [ 1.3466],\n",
      "        [ 4.4739]], dtype=torch.float64)\n",
      "------------ Solution n° :  3 ----------------\n",
      "R = \n",
      " tensor([[ 0.0106,  0.6776,  0.7353],\n",
      "        [ 0.3903, -0.6798,  0.6209],\n",
      "        [ 0.9206,  0.2804, -0.2717]], dtype=torch.float64)\n",
      "C = \n",
      " tensor([[1.1831],\n",
      "        [0.7881],\n",
      "        [0.5335]], dtype=torch.float64)\n",
      "------------ Solution n° :  4 ----------------\n",
      "R = \n",
      " tensor([[ 1.0000e+00, -5.3259e-10, -8.1739e-10],\n",
      "        [-5.3259e-10, -1.0000e+00,  1.0841e-09],\n",
      "        [-8.1739e-10, -1.0841e-09, -1.0000e+00]], dtype=torch.float64)\n",
      "C = \n",
      " tensor([[ 3.9427e-09],\n",
      "        [-5.2567e-09],\n",
      "        [ 6.0000e+00]], dtype=torch.float64)\n",
      "\n",
      "------------ Best solution : ----------------\n",
      "Solution n° : 4 \n",
      "\n",
      "R estimé = \n",
      " tensor([[ 1.0000e+00, -5.3259e-10, -8.1739e-10],\n",
      "        [-5.3259e-10, -1.0000e+00,  1.0841e-09],\n",
      "        [-8.1739e-10, -1.0841e-09, -1.0000e+00]], dtype=torch.float64) \n",
      "\n",
      "C estimé = \n",
      " tensor([[ 3.9427e-09],\n",
      "        [-5.2567e-09],\n",
      "        [ 6.0000e+00]], dtype=torch.float64) \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "============ Batch number :  3 =====================\n",
      "------------ Solution n° :  1 ----------------\n",
      "R = \n",
      " tensor([[ 0.9479, -0.2233,  0.2272],\n",
      "        [-0.3106, -0.8069,  0.5024],\n",
      "        [ 0.0712, -0.5468, -0.8342]], dtype=torch.float64)\n",
      "C = \n",
      " tensor([[-0.8971],\n",
      "        [-2.5319],\n",
      "        [ 3.5858]], dtype=torch.float64)\n",
      "------------ Solution n° :  2 ----------------\n",
      "R = \n",
      " tensor([[ 0.9479, -0.2233,  0.2272],\n",
      "        [-0.3106, -0.8069,  0.5024],\n",
      "        [ 0.0712, -0.5468, -0.8342]], dtype=torch.float64)\n",
      "C = \n",
      " tensor([[-0.8971],\n",
      "        [-2.5319],\n",
      "        [ 3.5858]], dtype=torch.float64)\n",
      "------------ Solution n° :  3 ----------------\n",
      "R = \n",
      " tensor([[ 1.0000e+00, -1.0077e-09, -5.0272e-11],\n",
      "        [-1.0077e-09, -1.0000e+00,  2.3665e-09],\n",
      "        [-5.0272e-11, -2.3665e-09, -1.0000e+00]], dtype=torch.float64)\n",
      "C = \n",
      " tensor([[ 1.0174e-09],\n",
      "        [-1.5377e-08],\n",
      "        [ 6.0000e+00]], dtype=torch.float64)\n",
      "------------ Solution n° :  4 ----------------\n",
      "R = \n",
      " tensor([[-0.2258, -0.6208, -0.7507],\n",
      "        [ 0.8493, -0.5030,  0.1605],\n",
      "        [-0.4772, -0.6013,  0.6408]], dtype=torch.float64)\n",
      "C = \n",
      " tensor([[ 3.8440],\n",
      "        [-0.9985],\n",
      "        [-2.5231]], dtype=torch.float64)\n",
      "\n",
      "------------ Best solution : ----------------\n",
      "Solution n° : 3 \n",
      "\n",
      "R estimé = \n",
      " tensor([[ 1.0000e+00, -1.0077e-09, -5.0272e-11],\n",
      "        [-1.0077e-09, -1.0000e+00,  2.3665e-09],\n",
      "        [-5.0272e-11, -2.3665e-09, -1.0000e+00]], dtype=torch.float64) \n",
      "\n",
      "C estimé = \n",
      " tensor([[ 1.0174e-09],\n",
      "        [-1.5377e-08],\n",
      "        [ 6.0000e+00]], dtype=torch.float64) \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "============ Batch number :  4 =====================\n",
      "------------ Solution n° :  1 ----------------\n",
      "R = \n",
      " tensor([[ 1.0000e+00, -1.9155e-08,  8.1504e-08],\n",
      "        [-1.9155e-08, -1.0000e+00, -3.1246e-08],\n",
      "        [ 8.1504e-08,  3.1246e-08, -1.0000e+00]], dtype=torch.float64)\n",
      "C = \n",
      " tensor([[-5.6487e-07],\n",
      "        [ 2.3271e-07],\n",
      "        [ 6.0000e+00]], dtype=torch.float64)\n",
      "------------ Solution n° :  2 ----------------\n",
      "R = \n",
      " tensor([[-0.7280, -0.6391,  0.2481],\n",
      "        [ 0.6374, -0.7642, -0.0982],\n",
      "        [ 0.2524,  0.0867,  0.9637]], dtype=torch.float64)\n",
      "C = \n",
      " tensor([[-0.2685],\n",
      "        [-0.0232],\n",
      "        [-7.3556]], dtype=torch.float64)\n",
      "------------ Solution n° :  3 ----------------\n",
      "R = \n",
      " tensor([[-0.3484, -0.8644, -0.3625],\n",
      "        [-0.2431,  0.4568, -0.8557],\n",
      "        [ 0.9053, -0.2100, -0.3692]], dtype=torch.float64)\n",
      "C = \n",
      " tensor([[ 1.2356],\n",
      "        [ 0.0472],\n",
      "        [-0.6266]], dtype=torch.float64)\n",
      "------------ Solution n° :  4 ----------------\n",
      "R = \n",
      " tensor([[-0.3484, -0.8644, -0.3625],\n",
      "        [-0.2431,  0.4568, -0.8557],\n",
      "        [ 0.9053, -0.2100, -0.3692]], dtype=torch.float64)\n",
      "C = \n",
      " tensor([[ 1.2356],\n",
      "        [ 0.0472],\n",
      "        [-0.6266]], dtype=torch.float64)\n",
      "\n",
      "------------ Best solution : ----------------\n",
      "Solution n° : 1 \n",
      "\n",
      "R estimé = \n",
      " tensor([[ 1.0000e+00, -1.9155e-08,  8.1504e-08],\n",
      "        [-1.9155e-08, -1.0000e+00, -3.1246e-08],\n",
      "        [ 8.1504e-08,  3.1246e-08, -1.0000e+00]], dtype=torch.float64) \n",
      "\n",
      "C estimé = \n",
      " tensor([[-5.6487e-07],\n",
      "        [ 2.3271e-07],\n",
      "        [ 6.0000e+00]], dtype=torch.float64) \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "============ Batch number :  5 =====================\n",
      "------------ Solution n° :  1 ----------------\n",
      "R = \n",
      " tensor([[ 0.4080, -0.5543,  0.7255],\n",
      "        [-0.6302, -0.7459, -0.2155],\n",
      "        [ 0.6606, -0.3693, -0.6536]], dtype=torch.float64)\n",
      "C = \n",
      " tensor([[-2.0288],\n",
      "        [ 1.2602],\n",
      "        [ 0.7229]], dtype=torch.float64)\n",
      "------------ Solution n° :  2 ----------------\n",
      "R = \n",
      " tensor([[ 0.4080, -0.5543,  0.7255],\n",
      "        [-0.6302, -0.7459, -0.2155],\n",
      "        [ 0.6606, -0.3693, -0.6536]], dtype=torch.float64)\n",
      "C = \n",
      " tensor([[-2.0288],\n",
      "        [ 1.2602],\n",
      "        [ 0.7229]], dtype=torch.float64)\n",
      "------------ Solution n° :  3 ----------------\n",
      "R = \n",
      " tensor([[ 1.0000e+00, -2.7302e-08,  4.0839e-08],\n",
      "        [-2.7302e-08, -1.0000e+00,  3.3347e-08],\n",
      "        [ 4.0839e-08, -3.3347e-08, -1.0000e+00]], dtype=torch.float64)\n",
      "C = \n",
      " tensor([[-3.0252e-07],\n",
      "        [-2.1826e-07],\n",
      "        [ 6.0000e+00]], dtype=torch.float64)\n",
      "------------ Solution n° :  4 ----------------\n",
      "R = \n",
      " tensor([[ 0.7940,  0.6078,  0.0079],\n",
      "        [-0.3992,  0.5116,  0.7608],\n",
      "        [ 0.4584, -0.6073,  0.6489]], dtype=torch.float64)\n",
      "C = \n",
      " tensor([[ 0.5200],\n",
      "        [-3.0412],\n",
      "        [-4.8114]], dtype=torch.float64)\n",
      "\n",
      "------------ Best solution : ----------------\n",
      "Solution n° : 3 \n",
      "\n",
      "R estimé = \n",
      " tensor([[ 1.0000e+00, -2.7302e-08,  4.0839e-08],\n",
      "        [-2.7302e-08, -1.0000e+00,  3.3347e-08],\n",
      "        [ 4.0839e-08, -3.3347e-08, -1.0000e+00]], dtype=torch.float64) \n",
      "\n",
      "C estimé = \n",
      " tensor([[-3.0252e-07],\n",
      "        [-2.1826e-07],\n",
      "        [ 6.0000e+00]], dtype=torch.float64) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "def distance(pt, pt_estimation):\n",
    "  # input : pt = [u,v] 2D point in the image  (2,1)\n",
    "  #         pt_estimation = [u_est,v_est] 2D point estimated by P3P (2,1)  \n",
    "\n",
    "  erreur = torch.tensor(0, dtype=torch.float64)  # Initialize error as a tensor\n",
    "  for i in range(len(pt)): \n",
    "    erreur = erreur + (pt[i] - pt_estimation[i])**2  \n",
    "  return torch.sqrt(erreur)\n",
    "\n",
    "\n",
    "def affichage_erreur(solutions,points2D,points3D,A) : \n",
    "  \n",
    "  # Compute the error of estimation for each points after the P3P algorithm \n",
    "\n",
    "  # solutions : solution matrix returned by P3P (4*3*4)\n",
    "  # points 3D : 4 pts 3D used for P3P - list of tensors (batch_size, 3)\n",
    "  # points 2D : 4 pts 2D used for P3P (image of the 3D points)\n",
    "  batch_size_ = solutions.shape[0]\n",
    "\n",
    "  for k in range(batch_size_):  # Iterate over the batch size\n",
    "    print(\"\\n\\n\")\n",
    "    print(\"============ Batch number : \", k+1,\"=====================\")\n",
    "\n",
    "    P1 = points3D[0][k]\n",
    "    P2 = points3D[1][k]\n",
    "    P3 = points3D[2][k]\n",
    "    P4 = points3D[3][k]\n",
    "    A_ = A[k,:,:]\n",
    "\n",
    "    erreurs = []\n",
    "    nb_sol = 0\n",
    "\n",
    "    for i in range(4):  # Iterate over the 4 solutions: \n",
    "      R = solutions[k,i,:,1:] # (3,3)\n",
    "      C = solutions[k,i,:,:1] # (3,1)\n",
    "      \n",
    "      #if not R[0,0].isnan() : \n",
    "      nb_sol += 1 \n",
    "      print(\"------------ Solution n° : \",nb_sol,\"----------------\")\n",
    "      print(\"R = \\n\",R,)\n",
    "      print(\"C = \\n\",C,)\n",
    "\n",
    "      \n",
    "      p1_P3P = projection3D2D(P1,C,R,A_)\n",
    "      p2_P3P = projection3D2D(P2,C,R,A_)\n",
    "      p3_P3P = projection3D2D(P3,C,R,A_)\n",
    "      p4_P3P = projection3D2D(P4,C,R,A_)\n",
    "      pt_2D_P3P = [p1_P3P,p2_P3P,p3_P3P,p4_P3P]   # (4,2)\n",
    "\n",
    "\n",
    "      erreurs.append([0])\n",
    "      for j in range(len(points2D)):\n",
    "          erreur_pt = torch.where(R[0,0].isnan(),float('inf'),distance(points2D[j][k],pt_2D_P3P[j]))\n",
    "          erreurs[i]+=erreur_pt\n",
    "    \n",
    "    \n",
    "        \n",
    "    indice_min = 0\n",
    "    min = erreurs[0]\n",
    "    for i in range(1,len(erreurs)) :\n",
    "      if erreurs[i]<min :\n",
    "        min = erreurs[i]\n",
    "        indice_min = i\n",
    "\n",
    "    R_opti = solutions[k,indice_min,:,1:] \n",
    "    C_opti = solutions[k,indice_min,:,:1]\n",
    "    print(\"\\n------------ Best solution : ----------------\")\n",
    "    print(\"Solution n° :\",indice_min+1,\"\\n\")\n",
    "    print(\"R estimé = \\n\", R_opti,\"\\n\")\n",
    "    print(\"C estimé = \\n\", C_opti, \"\\n\")\n",
    "\n",
    "affichage_erreur(solutions, [p1, p2, p3, p4], [P1,P2,P3, P4], A)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
